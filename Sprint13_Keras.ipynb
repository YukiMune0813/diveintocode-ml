{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "公式Example\n",
    "\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。\n",
    "\n",
    "\n",
    "【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "\n",
    "models/tutorials at master · tensorflow/models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】（アドバンス課題）様々な手法を実行\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "\n",
    "models/research at master · tensorflow/models\n",
    "\n",
    "\n",
    "google-research/google-research: Google AI Research\n",
    "\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "異なるフレームワークへの書き換え\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "\n",
    "Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "Iris（3種類全ての目的変数を使用して多値分類）\n",
    "House Prices\n",
    "MNIST\n",
    "\n",
    "Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()#irisデータ\n",
    "#二次元の表形式のデータ（テーブルデータ）、irisのdataと特徴量をdf化\n",
    "df = pd.DataFrame(data = iris.data , columns = iris.feature_names)\n",
    "#dfにtarget列を作成しtargetのデータを格納\n",
    "df['target'] = iris.target\n",
    "# df.loc[df['target'] == 0]\n",
    "# df.loc[df['target'] == 1]\n",
    "# df.loc[df['target'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfの50行から最後まで、特徴量までをXとする\n",
    "X = df.iloc[50: , :4].values\n",
    "\n",
    "#dfの50行から最後まで、targetをyとする\n",
    "y = df.iloc[50: , -1].values\n",
    "\n",
    "#yの2を０にして、0,1にして2値分類の形に整える\n",
    "y[y==2]=0\n",
    "\n",
    "#train_test_splitでXとyをトレインデータ：テストデータ＝8:2で分ける\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "               X , y , test_size = 0.2)\n",
    "\n",
    "#train_test_splitでX_trainとy_trainをトレインデータ：バリデーションデータ=8:2で分ける\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "               X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras\n",
    "#Kerasパッケージは単体では動かす事ができない。バックエンドとしてTensorFlowなどの低レベルニューラルネットワークライブラリが必要\n",
    "#from keras.modelsというのはモデルが色々はいったモジュール\n",
    "from keras.models import Sequential\n",
    "#レイヤーはkeras.layersにまとめられていて、その中のDenseを使う事を上で宣言\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/100\n",
      "64/64 [==============================] - 1s 9ms/step - loss: 2.3814 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 0s 5ms/step - loss: 0.6916 - accuracy: 0.5312\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.5469\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.5156\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.5469\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 0s 3ms/step - loss: 0.6109 - accuracy: 0.7812\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.7812\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.7969\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.8438\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6562\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.9062\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.9375\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7812\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8906\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.8281\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.9688\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.9531\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.9531\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8906\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.9219\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.9062\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.9062\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8750\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4151 - accuracy: 0.9219\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4089 - accuracy: 0.9688\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.9062\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.9219\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.9531\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3979 - accuracy: 0.9531\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.9531\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.9844\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3835 - accuracy: 0.9062\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.9531\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.9375\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8906\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.9062\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.9062\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.9531\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3384 - accuracy: 0.9531\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.9531\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.9531\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.9688\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.9531\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9688\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9688\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2971 - accuracy: 0.9531\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.9531\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9688\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.9531\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.9531\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.9375\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.9688\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.9531\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.9531\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9688\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2611 - accuracy: 0.9531\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2638 - accuracy: 0.9688\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2595 - accuracy: 0.9531\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2518 - accuracy: 0.9219\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9531\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.9688\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2531 - accuracy: 0.9531\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9688\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9688\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9531\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9375\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.9531\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2338 - accuracy: 0.9531\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2356 - accuracy: 0.9688\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2323 - accuracy: 0.9531\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2289 - accuracy: 0.9531\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2240 - accuracy: 0.9844\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9844\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9688\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.9688\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9531\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9688\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.9531\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2109 - accuracy: 0.9688\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9688\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9531\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2015 - accuracy: 0.9688\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9531\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2091 - accuracy: 0.9531\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.2023 - accuracy: 0.9688\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1989 - accuracy: 0.9531\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1980 - accuracy: 0.9688\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1993 - accuracy: 0.9688\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1934 - accuracy: 0.9688\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1971 - accuracy: 0.9688\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1954 - accuracy: 0.9531\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1963 - accuracy: 0.9688\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session( )\n",
    "\n",
    "#何も設定されていない真っ新なSequentialモデルを作るには、単純にSequential()\n",
    "model = Sequential()\n",
    "\n",
    "#Sequentialが持っているaddメソッドでレイヤーを追加、addメソッドの引数にDenseレイヤーを与える\n",
    "#unitsはDenseを作る時に唯一必須のパラメータ\n",
    "#入力値とは解析したいデータそのものの事、入力シェイプにはこの入力値の次元数を与える\n",
    "#２つ目以降のDenseにinput_shapeは不要。\n",
    "#Denseは全結合ニューラルネットワークなので、自動的に次の全てのunitsに接続される。\n",
    "#model.add(Dense(units=1 , input_shape = (4 , )))\n",
    "\n",
    "#2クラス分類、sigmoid\n",
    "#model.add(Activation(\"sigmoid\")) #model.add(Dense(units=1 , input_shape = (4 , ), activation=\"sigmoid\"))\n",
    "model.add(Dense(units=1 , input_shape = (4 , ),activation=\"sigmoid\")) \n",
    "\n",
    "#モデルの要約を出力します．utils.print_summaryへのショートカット\n",
    "#作成したニューラルネットワークのモデル形状の概要を表示\n",
    "#Model: \"sequential_1\"の部分の表示\n",
    "model.summary()\n",
    "\n",
    "#訓練プロセスを作る（コンパイル：compile）\n",
    "#損失関数及び正解に近づける修正方法である最適化を選択するのが「訓練プロセスの作成」でSequentialが持つcompile関数で設定\n",
    "#loss=損失関数で、名前を文字列で指定（もしくは誤差オブジェクトを直接指定)\n",
    "#optimizerには最適化方法を名前で指定(もしくは最適化オブジェクトを直接指定）\n",
    "#metricsは評価関数：accuracy\n",
    "#2クラス分類なので二値交差エントロピー\n",
    "model.compile(loss = \"binary_crossentropy\" , \n",
    "             optimizer = Adam(lr = 0.01) , \n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "#訓練プロセス（コンパイル）を完了し、いよいよモデルの学習を開始する。\n",
    "#学習するためには「入力シェイプで指定した次元数がある入力データ」と「その入力データで期待する答え」が1対となったデータの配列が必要\n",
    "#Kerasの慣習的に入力データはx_train、期待する答えはy_trainと表す\n",
    "#epochsはx_trainの入力データ全部を1塊として、その塊を学習し直す回数を指定。\n",
    "#同じデータセットを何度も再学習させる事でモデル内のパラメータ（＝重み）をそのデータセットに合うよう自動的に調整される。\n",
    "#batch_sizeはx_trainを小分けにする場合に与え、その小分けにした1セットを「サブバッチ」と呼び、「過学習」を防ぐ。\n",
    "#fitメソッドの戻り値はHistoryオブジェクトとなり、フィッティングの結果を保持\n",
    "#fitメソッドを実行すると、pythonのコンソール画面にその学習結果が1epoch毎に出力\n",
    "#重要なのが「loss」、これはコンパイル時に引数で与えたloss（損失関数）が出した正解とのズレの値\n",
    "#この値が小さい程訓練データに対して良くフィッティングしている事を意味する。\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 100 , \n",
    "                   verbose = 1)\n",
    "#lossが減っているので訓練データに良くフィットしていると思う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_expect [0.03793284 0.20415786 0.52261084 0.15046191 0.71961474 0.9406971\n",
      " 0.13020998 0.1105088  0.9301784  0.7962742  0.32810578 0.25937724\n",
      " 0.8958205  0.9401467  0.0311316  0.87506694]\n",
      "y_pred [0 0 1 0 1 1 0 0 1 1 0 0 1 1 0 1]\n",
      "精度 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "#Sequencialが持つpredictメソッド\n",
    "y_pred_expect= model.predict(X_val)[: , 0]#全ての行の0列目を取得=0列目を行に変換\n",
    "\n",
    "y_pred = np.where(y_pred_expect > 0.5 , 1 , 0)#0.5を超えている値を1、下回ると0mを取得\n",
    "print(\"y_pred_expect\" , y_pred_expect)\n",
    "print(\"y_pred\" , y_pred)\n",
    "print(\"精度\" , precision_score(y_val , y_pred))#yのバリデーションとy-predの精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03793284],\n",
       "       [0.20415786],\n",
       "       [0.52261084],\n",
       "       [0.15046191],\n",
       "       [0.71961474],\n",
       "       [0.9406971 ],\n",
       "       [0.13020998],\n",
       "       [0.1105088 ],\n",
       "       [0.9301784 ],\n",
       "       [0.7962742 ],\n",
       "       [0.32810578],\n",
       "       [0.25937724],\n",
       "       [0.8958205 ],\n",
       "       [0.9401467 ],\n",
       "       [0.0311316 ],\n",
       "       [0.87506694]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_val)\n",
    "#valは16\n",
    "#testは20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = iris.data , columns = iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "X = df.iloc[: , :4].values\n",
    "y = df.iloc[: , -1].values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])#np.newaxisで新たな次元の追加\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "               X , y , test_size = 0.2)\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "                X_train , y_train , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "#ネットワーク構造をkeras.layersで定義する部分の２つを書いておいて、入力と出力がいくつあるのかkeras.Model()で定義\n",
    "input_data = tf.keras.layers.Input(shape=(4 , ))\n",
    "\n",
    "#学習データとテストデータのようにkerasの外からkerasモデルに渡すデータは必ず最初にkeras.layers.Input()で受け取る\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(input_data)\n",
    "\n",
    "#加える層の右にその層への入力を（）付きで与えるように書いて、1層ずつ増やす\n",
    "#多クラス分類：reluを活性化関数\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(10 , activation=tf.nn.relu)(x)\n",
    "\n",
    "#多クラス分類なのでソフトマックス\n",
    "output = tf.keras.layers.Dense(3 , activation=tf.nn.softmax)(x)\n",
    "#入力と出力がいくつあるのかkeras.Model()で定義、今回は一個ずつ\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.5188 - acc: 0.8333\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.5560 - acc: 0.6979\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3520 - acc: 0.8438\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.3445 - acc: 0.8750\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1737 - acc: 0.9375\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2284 - acc: 0.8854\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1286 - acc: 0.9583\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.2400 - acc: 0.9062\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1099 - acc: 0.9479\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1500 - acc: 0.9375\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1159 - acc: 0.9271\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1540 - acc: 0.9375\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.3106 - acc: 0.8854\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1203 - acc: 0.9583\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1083 - acc: 0.9688\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.1677 - acc: 0.9271\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1512 - acc: 0.9583\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1s 5ms/sample - loss: 0.1416 - acc: 0.9375\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0777 - acc: 0.9792\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0621 - acc: 0.9688\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 1s 6ms/sample - loss: 0.0723 - acc: 0.9688 0s - loss: 0.0142 - \n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1359 - acc: 0.9583\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1294 - acc: 0.9583\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1561 - acc: 0.9375\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 1s 6ms/sample - loss: 0.0870 - acc: 0.9688\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.1713 - acc: 0.9167\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 1s 5ms/sample - loss: 0.1115 - acc: 0.9375\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0788 - acc: 0.9583\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0673 - acc: 0.9688\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1254 - acc: 0.9688\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0572 - acc: 0.9792\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0775 - acc: 0.9688\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1376 - acc: 0.9583\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0920 - acc: 0.9583\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0493 - acc: 0.9792\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1013 - acc: 0.9688\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1165 - acc: 0.9583\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0647 - acc: 0.9792\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 0s 5ms/sample - loss: 0.0802 - acc: 0.9792\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.1038 - acc: 0.9583\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2060 - acc: 0.9167\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0685 - acc: 0.9688\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 0s 4ms/sample - loss: 0.0353 - acc: 0.9896\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.2026 - acc: 0.9375\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.1674 - acc: 0.9167\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0610 - acc: 0.9792\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 0s 2ms/sample - loss: 0.0778 - acc: 0.9688\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 0s 3ms/sample - loss: 0.0388 - acc: 0.9896\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "#categorical_crossentropyはクロスエントロピー、多クラス分類\n",
    "model.compile(loss=\"categorical_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01) , \n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 50 , \n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00         7\n",
      " versicolor       1.00      1.00      1.00         9\n",
      "  virginica       1.00      1.00      1.00         8\n",
      "\n",
      "avg / total       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_expect_2 = model.predict(X_val)\n",
    "y_pred = np.where(y_pred_expect_2 > 0.5 , 1 , 0)\n",
    "print(classification_report(y_val , y_pred, target_names=iris.target_names))\n",
    "\n",
    "#クラス分類をそういった情報を簡単に要約して出力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "X = df.loc[: , [\"GrLivArea\" , \"YearBuilt\"]]\n",
    "y = df.loc[: , \"SalePrice\"]\n",
    "y = np.log(y)\n",
    "X_train , X_test , y_train , y_test = train_test_split(\n",
    "                X , y , test_size=0.2)\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "                X_train , y_train , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 934 samples, validate on 934 samples\n",
      "Epoch 1/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 3183.5888 - val_loss: 8.2273\n",
      "Epoch 2/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 3.9348 - val_loss: 1.8929\n",
      "Epoch 3/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 2.0198 - val_loss: 0.6007\n",
      "Epoch 4/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 7.8112 - val_loss: 4.4395\n",
      "Epoch 5/10\n",
      "934/934 [==============================] - 4s 5ms/sample - loss: 17.5261 - val_loss: 0.6717\n",
      "Epoch 6/10\n",
      "934/934 [==============================] - 3s 3ms/sample - loss: 0.9846 - val_loss: 0.4830\n",
      "Epoch 7/10\n",
      "934/934 [==============================] - 4s 5ms/sample - loss: 0.6416 - val_loss: 0.2324\n",
      "Epoch 8/10\n",
      "934/934 [==============================] - 4s 4ms/sample - loss: 0.5494 - val_loss: 0.4379\n",
      "Epoch 9/10\n",
      "934/934 [==============================] - 9s 9ms/sample - loss: 60.1127 - val_loss: 0.1630\n",
      "Epoch 10/10\n",
      "934/934 [==============================] - 5s 6ms/sample - loss: 0.1642 - val_loss: 0.1653\n"
     ]
    }
   ],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu , input_shape = (2 , )))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10 , activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1 , ))\n",
    "\n",
    "#回帰、平均二乗誤差\n",
    "model.compile(loss=\"mean_squared_error\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01))\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 1 , \n",
    "                   epochs = 10 , \n",
    "                   verbose = 1 , \n",
    "                   validation_data = (X_train , y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1 , 784)\n",
    "X_test = X_test.reshape(-1 , 784)\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "# y_train = tf.one_hot(y_train , depth=3 ,dtype=None)\n",
    "# y_test = tf.one_hot(y_test , depth=3 , dtype=None)\n",
    "X_train = X_train.reshape(-1 , 28 , 28 , 1)\n",
    "X_test = X_test.reshape(-1 , 28 , 28 , 1)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session( )\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(28 , 28 , 1))\n",
    "con1 = tf.keras.layers.Conv2D(3 , kernel_size = (2,2)  , activation = tf.nn.relu)(input_data)\n",
    "max_p1 = tf.keras.layers.MaxPooling2D((3,3) , strides=(1,1))(con1)\n",
    "con2 = tf.keras.layers.Conv2D(3 , (2,2) , activation = tf.nn.relu)(max_p1)\n",
    "max_p2 = tf.keras.layers.MaxPooling2D((3,3) , strides = (2,2))(con2)\n",
    "fla = tf.keras.layers.Flatten()(max_p2)\n",
    "x = tf.keras.layers.Dense(100 , activation=tf.nn.relu)(fla)\n",
    "x = tf.keras.layers.Dense(50 , activation=tf.nn.relu)(x)\n",
    "x = tf.keras.layers.Dense(20 , activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(10 , activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs = input_data , outputs = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 27, 27, 3)         15        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 3)         39        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 363)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               36400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 42,734\n",
      "Trainable params: 42,734\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 21s 431us/sample - loss: 0.3397 - acc: 0.8935\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 25s 528us/sample - loss: 0.1315 - acc: 0.9605\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 23s 479us/sample - loss: 0.1005 - acc: 0.9688\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 25s 529us/sample - loss: 0.0828 - acc: 0.9749\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 22s 461us/sample - loss: 0.0824 - acc: 0.9754\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 22s 449us/sample - loss: 0.0787 - acc: 0.9760\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 25s 513us/sample - loss: 0.0723 - acc: 0.9785\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 24s 505us/sample - loss: 0.0731 - acc: 0.9790\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 28s 594us/sample - loss: 0.0659 - acc: 0.9818\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 22s 449us/sample - loss: 0.0656 - acc: 0.9812\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss=\"categorical_crossentropy\" , \n",
    "             optimizer = tf.train.AdamOptimizer(learning_rate=0.01) , \n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train , y_train , \n",
    "                   batch_size = 100 , \n",
    "                   epochs = 10 , \n",
    "                   verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
