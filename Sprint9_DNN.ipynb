{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ディープニューラルネットワークスクラッチ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回は3層のニューラルネットワークを作成しましたが、今回はこれを任意の層数に拡張しやすいものに書き換えていきます。その上で、活性化関数や初期値、最適化手法について発展的なものを扱えるようにしていきます。\n",
    "\n",
    "\n",
    "このようなスクラッチを行うことで、今後各種フレームワークを利用していくにあたり、内部の動きが想像できることを目指します。\n",
    "\n",
    "\n",
    "名前は新しくScratchDeepNeuralNetrowkClassifierクラスとしてください。\n",
    "\n",
    "\n",
    "層などのクラス化  \n",
    "クラスにまとめて行くことで、構成を変更しやすい実装にしていきます。\n",
    "\n",
    "\n",
    "手を加える箇所\n",
    "\n",
    "- 層の数\n",
    "- 層の種類（今後畳み込み層など他のタイプの層が登場する）\n",
    "- 活性化関数の種類\n",
    "- 重みやバイアスの初期化方法\n",
    "- 最適化手法\n",
    "\n",
    "そのために、全結合層、各種活性化関数、重みやバイアスの初期化、最適化手法それぞれのクラスを作成します。\n",
    "\n",
    "\n",
    "実装方法は自由ですが、簡単な例を紹介します。サンプルコード1のように全結合層と活性化関数のインスタンスを作成し、サンプルコード2,3のようにして使用します。それぞれのクラスについてはこのあと解説します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】全結合層のクラス化\n",
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1 , 784)#(60000, 784)\n",
    "X_test = X_test.reshape(-1 , 784)#(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1557a6b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28 , 28)\n",
    "#X_train[index] : (784,)\n",
    "#image : (28,28)\n",
    "plt.imshow(image , \"gray\")\n",
    "plt.title(\"label : {}\".format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEBdJREFUeJzt3X2sVHV+x/H3R9S0IorEipQFWazFVWPZDWLrmlVDWcVo9PqwkdaEBiumK402LanlHzUt1taHVqJxwagLyS5qqhak20UrKnZtiFfElYVl1xpU9BbWIPLgA4H77R/3sHvFO78Z5ukM9/d5JTd3Zr7nzPky4XPPmfmdMz9FBGaWn8PKbsDMyuHwm2XK4TfLlMNvlimH3yxTDr9Zphz+Q5ykTZL+uMZlQ9Lv1bmdute1zuTwW8tJelHSZ5J2FT8by+7JHH5rn9kRcXTxM6HsZszhH1QkTZb0P5K2S+qRdL+kIw9Y7GJJb0v6UNJdkg7rt/5MSRskfSRphaST2vxPsDZy+AeXfcBfAccDfwRMAb57wDJdwCTgG8BlwEwASZcDc4ErgN8BXgaW1LJRSbdIWl5lsX8s/uD8RNL5Nf1rrKXkc/sPbZI2AX8eEf81QO1m4LyI6CruBzAtIn5c3P8ucGVETJH0n8C/RcTDRe0wYBfwtYh4p1j3lIh4q44ezwbWA3uAa4D7gYkR8b8H/y+2ZvGefxCR9PuSlkv6P0k7gDvoOwro771+t98Bfre4fRJwX/GWYTuwDRAwutG+ImJ1ROyMiM8jYhHwE+DiRp/XGuPwDy4PAj+nbw99DH2H8TpgmTH9bo8FPihuvwfcEBHD+/38dkS80oI+Y4C+rM0c/sFlGLAD2CXpVOAvBlhmjqTjJI0BbgIeLx7/HvB3kk4HkHSspKsbbUjScEkXSvotSYdL+lPgW8CKRp/bGuPwDy5/A/wJsBN4iN8Eu7+lwGvAWuA/gIcBIuJp4J+Ax4q3DOuAabVsVNLc4jODgRwB/APwK+BD4C+ByyPCY/0l8wd+Zpnynt8sUw6/WaYcfrNMOfxmmTq8nRsrzhIzsxaKiJrOoWhozy/pIkkbJb0l6ZZGnsvM2qvuoT5JQ4BfAFOBzcCrwPSIWJ9Yx3t+sxZrx55/MvBWRLwdEXuAx+i7SszMDgGNhH80X7xIZDMDXAQiaZakbkndDWzLzJqskQ/8Bjq0+NJhfUQsBBaCD/vNOkkje/7NfPEKsa/wmyvEzKzDNRL+V4FTJH21+Kqoa4BlzWnLzFqt7sP+iNgraTZ9l2YOAR6JiJ81rTMza6m2XtXn9/xmrdeWk3zM7NDl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph98sU3VP0W2HhiFDhiTrxx57bEu3P3v27Iq1o446KrnuhAkTkvUbb7wxWb/77rsr1qZPn55c97PPPkvW77zzzmT99ttvT9Y7QUPhl7QJ2AnsA/ZGxKRmNGVmrdeMPf8FEfFhE57HzNrI7/nNMtVo+AN4VtJrkmYNtICkWZK6JXU3uC0za6JGD/u/GREfSDoBeE7SzyNiVf8FImIhsBBAUjS4PTNrkob2/BHxQfF7K/A0MLkZTZlZ69UdfklDJQ3bfxv4NrCuWY2ZWWs1ctg/Enha0v7n+WFE/LgpXQ0yY8eOTdaPPPLIZP2cc85J1s8999yKteHDhyfXvfLKK5P1Mm3evDlZnz9/frLe1dVVsbZz587kum+88Uay/tJLLyXrh4K6wx8RbwN/0MRezKyNPNRnlimH3yxTDr9Zphx+s0w5/GaZUkT7TrobrGf4TZw4MVlfuXJlst7qy2o7VW9vb7I+c+bMZH3Xrl11b7unpydZ/+ijj5L1jRs31r3tVosI1bKc9/xmmXL4zTLl8JtlyuE3y5TDb5Yph98sUw6/WaY8zt8EI0aMSNZXr16drI8fP76Z7TRVtd63b9+erF9wwQUVa3v27Emum+v5D43yOL+ZJTn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFOeorsJtm3blqzPmTMnWb/kkkuS9ddffz1Zr/YV1ilr165N1qdOnZqs7969O1k//fTTK9Zuuumm5LrWWt7zm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZ8vX8HeCYY45J1qtNJ71gwYKKteuuuy657rXXXpusL1myJFm3ztO06/klPSJpq6R1/R4bIek5Sb8sfh/XSLNm1n61HPZ/H7jogMduAZ6PiFOA54v7ZnYIqRr+iFgFHHj+6mXAouL2IuDyJvdlZi1W77n9IyOiByAieiSdUGlBSbOAWXVux8xapOUX9kTEQmAh+AM/s05S71DfFkmjAIrfW5vXkpm1Q73hXwbMKG7PAJY2px0za5eqh/2SlgDnA8dL2gzcCtwJPCHpOuBd4OpWNjnY7dixo6H1P/7447rXvf7665P1xx9/PFnv7e2te9tWrqrhj4jpFUpTmtyLmbWRT+81y5TDb5Yph98sUw6/WaYcfrNM+ZLeQWDo0KEVa88880xy3fPOOy9ZnzZtWrL+7LPPJuvWfp6i28ySHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKY/zD3Inn3xysr5mzZpkffv27cn6Cy+8kKx3d3dXrD3wwAPJddv5f3Mw8Ti/mSU5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTHufPXFdXV7L+6KOPJuvDhg2re9tz585N1hcvXpys9/T01L3twczj/GaW5PCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTHmc35LOOOOMZP3ee+9N1qdMqX8y5wULFiTr8+bNS9bff//9urd9KGvaOL+kRyRtlbSu32O3SXpf0tri5+JGmjWz9qvlsP/7wEUDPP4vETGx+PlRc9sys1arGv6IWAVsa0MvZtZGjXzgN1vST4u3BcdVWkjSLEndkip/mZuZtV294X8QOBmYCPQA91RaMCIWRsSkiJhU57bMrAXqCn9EbImIfRHRCzwETG5uW2bWanWFX9Kofne7gHWVljWzzlR1nF/SEuB84HhgC3BrcX8iEMAm4IaIqHpxtcf5B5/hw4cn65deemnFWrXvCpDSw9UrV65M1qdOnZqsD1a1jvMfXsMTTR/g4YcPuiMz6yg+vdcsUw6/WaYcfrNMOfxmmXL4zTLlS3qtNJ9//nmyfvjh6cGovXv3JusXXnhhxdqLL76YXPdQ5q/uNrMkh98sUw6/WaYcfrNMOfxmmXL4zTLl8JtlqupVfZa3M888M1m/6qqrkvWzzjqrYq3aOH4169evT9ZXrVrV0PMPdt7zm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZ8jj/IDdhwoRkffbs2cn6FVdckayfeOKJB91Trfbt25es9/Skvy2+t7e3me0MOt7zm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZqjrOL2kMsBg4EegFFkbEfZJGAI8D4+ibpvs7EfFR61rNV7Wx9OnTB5pIuU+1cfxx48bV01JTdHd3J+vz5s1L1pctW9bMdrJTy55/L/DXEfE14A+BGyWdBtwCPB8RpwDPF/fN7BBRNfwR0RMRa4rbO4ENwGjgMmBRsdgi4PJWNWlmzXdQ7/kljQO+DqwGRkZED/T9gQBOaHZzZtY6NZ/bL+lo4Eng5ojYIdU0HRiSZgGz6mvPzFqlpj2/pCPoC/4PIuKp4uEtkkYV9VHA1oHWjYiFETEpIiY1o2Eza46q4VffLv5hYENE3NuvtAyYUdyeASxtfntm1ipVp+iWdC7wMvAmfUN9AHPpe9//BDAWeBe4OiK2VXmuLKfoHjlyZLJ+2mmnJev3339/sn7qqacedE/Nsnr16mT9rrvuqlhbujS9v/AlufWpdYruqu/5I+K/gUpPNuVgmjKzzuEz/Mwy5fCbZcrhN8uUw2+WKYffLFMOv1mm/NXdNRoxYkTF2oIFC5LrTpw4MVkfP358XT01wyuvvJKs33PPPcn6ihUrkvVPP/30oHuy9vCe3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLVDbj/GeffXayPmfOnGR98uTJFWujR4+uq6dm+eSTTyrW5s+fn1z3jjvuSNZ3795dV0/W+bznN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0ylc04f1dXV0P1Rqxfvz5ZX758ebK+d+/eZD11zf327duT61q+vOc3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTKliEgvII0BFgMnAr3Awoi4T9JtwPXAr4pF50bEj6o8V3pjZtawiFAty9US/lHAqIhYI2kY8BpwOfAdYFdE3F1rUw6/WevVGv6qZ/hFRA/QU9zeKWkDUO5X15hZww7qPb+kccDXgdXFQ7Ml/VTSI5KOq7DOLEndkrob6tTMmqrqYf+vF5SOBl4C5kXEU5JGAh8CAfw9fW8NZlZ5Dh/2m7VY097zA0g6AlgOrIiIeweojwOWR8QZVZ7H4TdrsVrDX/WwX5KAh4EN/YNffBC4Xxew7mCbNLPy1PJp/7nAy8Cb9A31AcwFpgMT6Tvs3wTcUHw4mHou7/nNWqyph/3N4vCbtV7TDvvNbHBy+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFPtnqL7Q+CdfvePLx7rRJ3aW6f2Be6tXs3s7aRaF2zr9fxf2rjUHRGTSmsgoVN769S+wL3Vq6zefNhvlimH3yxTZYd/YcnbT+nU3jq1L3Bv9Sqlt1Lf85tZecre85tZSRx+s0yVEn5JF0naKOktSbeU0UMlkjZJelPS2rLnFyzmQNwqaV2/x0ZIek7SL4vfA86RWFJvt0l6v3jt1kq6uKTexkh6QdIGST+TdFPxeKmvXaKvUl63tr/nlzQE+AUwFdgMvApMj4j1bW2kAkmbgEkRUfoJIZK+BewCFu+fCk3SPwPbIuLO4g/ncRHxtx3S220c5LTtLeqt0rTyf0aJr10zp7tvhjL2/JOBtyLi7YjYAzwGXFZCHx0vIlYB2w54+DJgUXF7EX3/edquQm8dISJ6ImJNcXsnsH9a+VJfu0RfpSgj/KOB9/rd30yJL8AAAnhW0muSZpXdzABG7p8Wrfh9Qsn9HKjqtO3tdMC08h3z2tUz3X2zlRH+gaYS6qTxxm9GxDeAacCNxeGt1eZB4GT65nDsAe4ps5liWvkngZsjYkeZvfQ3QF+lvG5lhH8zMKbf/a8AH5TQx4Ai4oPi91bgafrepnSSLftnSC5+by25n1+LiC0RsS8ieoGHKPG1K6aVfxL4QUQ8VTxc+ms3UF9lvW5lhP9V4BRJX5V0JHANsKyEPr5E0tDigxgkDQW+TedNPb4MmFHcngEsLbGXL+iUadsrTStPya9dp013X8oZfsVQxr8CQ4BHImJe25sYgKTx9O3toe9y5x+W2ZukJcD59F3yuQW4Ffh34AlgLPAucHVEtP2Dtwq9nc9BTtveot4qTSu/mhJfu2ZOd9+Ufnx6r1mefIafWaYcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5ap/wfUztxCBq6dfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x135a8ed68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float)#float型に変換\n",
    "image -= 105.35 #意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image , \"gray\")\n",
    "plt.title(\"label : {}\".format(y_train[index]))\n",
    "plt.show()\n",
    "print(image)#値を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())#1.0\n",
    "print(X_train.min())#0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "             X_train , y_train_one_hot , test_size = 0.20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # バッチサイズ\n",
    "n_features = X_train.shape[1] # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "sigma = 0.01 # ガウス分布の標準偏差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(self , a):\n",
    "        c = np.max(a)\n",
    "        return 1 / (1 + np.exp(-(a/c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_value(n_features , n_nodes1,n_nodes2, n_output , sigma):\n",
    "    W1 = sigma * np.random.rand(n_features , n_nodes1)#一層目の重み\n",
    "    W2 = sigma * np.random.rand(n_nodes1 , n_nodes2)#二層目の重み\n",
    "    W_out = sigma * np.random.rand(n_nodes2 , n_output)#出力層の重み\n",
    "    b1 = np.zeros(n_nodes1)#一層目のバイアス\n",
    "    b2 = np.zeros(n_nodes2)#二層目のバイアス\n",
    "    b_out = np.zeros(n_output)#出力層のバイアス\n",
    "    return W1,W2,W_out,b1,b2,b_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 , W2 , W_out , b1 , b2 , b_out = initial_value(n_features , n_nodes1,n_nodes2, n_output , sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "# print(len(get_mini_batch)) # 2400\n",
    "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    A1 = np.dot(mini_X_train , W1) + b1\n",
    "    Z1 = np.tanh(A1)\n",
    "    A2 = np.dot(Z1 , W2) + b2\n",
    "    Z2 = np.tanh(A2)\n",
    "    A3 = np.dot(Z2 , W_out) + b_out\n",
    "    Z3 = Z = np.exp(A3) / np.sum(np.exp(A3))\n",
    "    L = -np.sum(mini_y_train * np.log(Z3)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "やること？\n",
    "- initializerのメソッドを使い、self.Wとself.Bを初期化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC():\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer , sigma=0.01):\n",
    "        self.optimizer = optimizer\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.initializer = initializer\n",
    "        self.sigma = sigma\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = self.initializer.W(self.n_nodes1 , self.n_nodes2)\n",
    "        self.B = self.initializer.B(self.n_nodes2)\n",
    "        self.X = None\n",
    "        self.dW = None\n",
    "        self.dB = None\n",
    "        self.hw = 0\n",
    "        self.hb = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "#         self.W = self.sigma * self.initializer.W(self.n_nodes1 , self.n_nodes2)\n",
    "#         self.B = self.sigma * self.initializer.B(self.n_nodes2)\n",
    "#         self.W2 = self.sigma * self.initializer.W(self.n_nodes1 , self.n_nodes2)\n",
    "#         self.B2 = self.initializer.B(self.n_nodes2)\n",
    "#         self.W_out = self.sigma * self.initializer.W(self.n_nodes2 , self.n_output)\n",
    "#         self.B_out = self.initializer.B(self.n_output)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"   \n",
    "        self.X = X\n",
    "        self.A = np.dot(self.X , self.W) + self.B\n",
    "        \n",
    "        return self.A\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dW = np.dot(self.X.T , dA)\n",
    "        self.dB = np.sum(dA , axis = 0)\n",
    "        dZ = np.dot(dA , self.W.T)\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 【問題2】初期化方法のクラス化\n",
    "初期化を行うコードをクラス化してください。\n",
    "\n",
    "\n",
    "前述のように、全結合層のコンストラクタに初期化方法のインスタンスを渡せるようにします。以下の雛形に必要なコードを書き加えていってください。標準偏差の値（sigma）はコンストラクタで受け取るようにすることで、全結合層のクラス内にこの値（sigma）を渡さなくてすむようになります。\n",
    "\n",
    "\n",
    "これまで扱ってきた初期化方法はSimpleInitializerクラスと名付けることにします。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer():\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        W = self.sigma * np.random.randn(n_nodes1 , n_nodes2)\n",
    "        \n",
    "        return W\n",
    "    def B(self, n_nodes2):\n",
    "        B = self.sigma * np.random.randn(n_nodes2)\n",
    "        \n",
    "        return B\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】最適化手法のクラス化\n",
    "最適化手法のクラス化を行なってください。\n",
    "\n",
    "\n",
    "最適化手法に関しても初期化方法同様に全結合層にインスタンスとして渡します。バックワードのときにself.optimizer.update(self)のように更新できるようにします。以下の雛形に必要なコードを書き加えていってください。\n",
    "\n",
    "\n",
    "これまで扱ってきた最適化手法はSGDクラス（Stochastic Gradient Descent、確率的勾配降下法）として作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD():\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "#         layer.W = self.W\n",
    "#         layer.B = self.B\n",
    "#         layer.dW = self.dW\n",
    "#         layer.dB = self.dB\n",
    "        \n",
    "        layer.W -= self.lr * layer.dW\n",
    "        layer.B -= self.lr * layer.dB\n",
    "        return layer.W , layer.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】活性化関数のクラス化\n",
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss():\n",
    "    def __init__(self):\n",
    "        self.loss = None\n",
    "        self.y = None\n",
    "        \n",
    "        \n",
    "    def forward(self , x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T\n",
    "        x = x - np.max(x)\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "    def backward(self , z , y):\n",
    "        self.dA = z - y\n",
    "        return self.dA\n",
    "    \n",
    "    def Loss(self , z , y):\n",
    "        loss =  -np.sum(y * np.log(z) + 1e-7) / y.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _sigmoid():\n",
    "    def __init__(self):\n",
    "        self.sig = None\n",
    "    \n",
    "    def forward(self , x):\n",
    "        c = np.max(x)\n",
    "        x = x / c\n",
    "        self.sig = 1 / (1 +  np.exp(-x))\n",
    "        return self.sig\n",
    "    \n",
    "    def backward(self , x):\n",
    "        self.dA = x * (1 - self.sig) * self.sig\n",
    "        return self.dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】ReLUクラスの作成\n",
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "\n",
    "ReLUは以下の数式です。\n",
    "$$\n",
    "% <![CDATA[\n",
    "f(x) = ReLU(x) = \\begin{cases}\n",
    "x  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "x\n",
    " : ある特徴量。スカラー\n",
    "\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "\n",
    "numpy.maximum — NumPy v1.15 Manual\n",
    "\n",
    "\n",
    "一方、バックプロパゲーションのための \n",
    "x\n",
    " に関する \n",
    "f\n",
    "(\n",
    "x\n",
    ")\n",
    " の微分は以下のようになります。\n",
    " \n",
    " $$\n",
    " % <![CDATA[\n",
    "\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}\n",
    "1  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$$\n",
    "\n",
    "数学的には微分可能ではないですが、 \n",
    "x\n",
    "=\n",
    "0\n",
    " のとき \n",
    "0\n",
    " とすることで対応しています。\n",
    "\n",
    "\n",
    "フォワード時の \n",
    "x\n",
    " の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self , x):\n",
    "        self.mask = (x <= 0)\n",
    "        self.A = x.copy()\n",
    "        self.A[self.mask] = 0\n",
    "        return self.A\n",
    "        \n",
    "    def backward(self , dA):\n",
    "        dA[self.mask] = 0\n",
    "        dA = dA\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】重みの初期値\n",
    "ここまでは重みやバイアスの初期値は単純にガウス分布で、標準偏差をハイパーパラメータとして扱ってきました。しかし、どのような値にすると良いかが知られています。シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。\n",
    "\n",
    "\n",
    "XavierInitializerクラスと、HeInitializerクラスを作成してください。\n",
    "\n",
    "\n",
    "Xavierの初期値\n",
    "Xavierの初期値における標準偏差 \n",
    "σ\n",
    " は次の式で求められます。\n",
    "\n",
    "\n",
    "σ\n",
    "=\n",
    "1\n",
    "√\n",
    "n\n",
    "\n",
    "n\n",
    " : 前の層のノード数\n",
    "\n",
    "\n",
    "《論文》\n",
    "\n",
    "\n",
    "Glorot, X., & Bengio, Y. (n.d.). Understanding the difficulty of training deep feedforward neural networks.\n",
    "\n",
    "\n",
    "Heの初期値\n",
    "Heの初期値における標準偏差 \n",
    "σ\n",
    " は次の式で求められます。\n",
    "\n",
    "\n",
    "σ\n",
    "=\n",
    "√\n",
    "2\n",
    "n\n",
    "\n",
    "n\n",
    " : 前の層のノード数\n",
    "\n",
    "\n",
    "《論文》\n",
    "\n",
    "\n",
    "He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer():\n",
    "    def __init__(self, n_nodes1,n_nodes2):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2        \n",
    "    \n",
    "    def W(self):\n",
    "        sigma = np.sqrt(1.0 / self.n_nodes1)\n",
    "        self.W = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        return self.W\n",
    "    \n",
    "    def B(self):\n",
    "        sigma = np.sqrt(1.0 / self.n_nodes1)\n",
    "        self.B = sigma * np.random.randn(self.n_nodes2)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    def __init__(self,n_nodes1,n_nodes2):\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "    \n",
    "    def W(self):\n",
    "        sigma =  np.sqrt(2.0 / n_nodes1)\n",
    "        self.W = sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        return self.W\n",
    "    \n",
    "    def B(self):\n",
    "        sigma =  np.sqrt(2.0 / n_nodes1)\n",
    "        self.W = sigma * np.random.randn(self.n_nodes2)\n",
    "        return self.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heの初期値\n",
    "w = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2.0 / n_nodes1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xavierの初期値\n",
    "w = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(1.0 / n_nodes1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題7】最適化手法\n",
    "学習率は学習過程で変化させていく方法が一般的です。基本的な手法である AdaGrad のクラスを作成してください。\n",
    "\n",
    "\n",
    "まず、これまで使ってきたSGDを確認します。\n",
    "$$\n",
    "W_i^{\\prime} = W_i - \\alpha E(\\frac{\\partial L}{\\partial W_i}) \\\\<br/>B_i^{\\prime} = B_i - \\alpha E(\\frac{\\partial L}{\\partial B_i})\n",
    "$$\n",
    "α\n",
    " : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "W\n",
    "i\n",
    " : \n",
    "W\n",
    "i\n",
    " に関する損失 \n",
    "L\n",
    " の勾配\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "B\n",
    "i\n",
    " : \n",
    "B\n",
    "i\n",
    " に関する損失 \n",
    "L\n",
    " の勾配\n",
    "\n",
    "\n",
    "E\n",
    "(\n",
    ")\n",
    " : ミニバッチ方向にベクトルの平均を計算\n",
    "\n",
    "\n",
    "続いて、AdaGradです。バイアスの数式は省略しますが、重みと同様のことをします。\n",
    "\n",
    "\n",
    "更新された分だけその重みに対する学習率を徐々に下げていきます。イテレーションごとの勾配の二乗和 \n",
    "H\n",
    " を保存しておき、その分だけ学習率を小さくします。\n",
    "\n",
    "\n",
    "学習率は重み一つひとつに対して異なることになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H_i^{\\prime}  = H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i})\\\\<br/>W_i^{\\prime} = W_i - \\alpha \\frac{1}{\\sqrt{H_i^{\\prime} }} E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "$$\n",
    "H\n",
    "i\n",
    " : i層目に関して、前のイテレーションまでの勾配の二乗和（初期値は0）\n",
    "\n",
    "\n",
    "H\n",
    "′\n",
    "i\n",
    " : 更新した \n",
    "H\n",
    "i\n",
    "\n",
    "《論文》\n",
    "\n",
    "\n",
    "Duchi JDUCHI, J., & Singer, Y. (2011). Adaptive Subgradient Methods for Online Learning and Stochastic Optimization * Elad Hazan. Journal of Machine Learning Research (Vol. 12).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad():\n",
    "    def __init__(self , lr , b_size):\n",
    "        self.lr = lr\n",
    "        self.hw = None\n",
    "        self.hb = None\n",
    "        self.b_size = b_size\n",
    "    \n",
    "    def update(self , layer):\n",
    "#         layer.W = self.W\n",
    "#         layer.B = self.B\n",
    "#         layer.dW = self.dW\n",
    "#         layer.dB = self.dB\n",
    "        \n",
    "        layer.hw += (layer.dW/self.b_size) * (layer.dW/self.b_size)\n",
    "        layer.W -= self.lr * (layer.dW/self.b_size) / (np.sqrt(layer.hw) + 1e-7)\n",
    "        layer.hb += (layer.dB/self.b_size) * (layer.dB/self.b_size)\n",
    "        layer.B -= self.lr * (layer.dB/self.b_size) / (np.sqrt(layer.hb) + 1e-7)\n",
    "        self.hw = layer.hw\n",
    "        self.hb = layer.hb\n",
    "        return layer.W, layer.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題8】クラスの完成\n",
    "任意の構成で学習と推定が行えるScratchDeepNeuralNetrowkClassifierクラスを完成させてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,epochs = 1,lr = 0.001 ,sigma = 0.01,n_nodes1= 400 , n_nodes2 = 200 , n_output = 10 , batch_size = 20, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        n_features = X_train.shape[1]\n",
    "        self.n_features = n_features\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.loss = []\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "   \n",
    "        Xavi = HeInitializer(self.n_nodes1 , self.n_nodes2)\n",
    "        self.W = Xavi.W()\n",
    "        self.B = Xavi.B()\n",
    "        optimizer = AdaGrad(self.lr , self.batch_size)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation1 = ReLU()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation2 = ReLU()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation3 = SoftmaxWithLoss()\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            self.get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "            for self.mini_X_train, self.mini_y_train in get_mini_batch:\n",
    "                A1 = self.FC1.forward(self.mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                \n",
    "                dA3 = self.activation3.backward(Z3 , self.mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "#                 dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "                self.c_loss = self.activation3.Loss(Z3 , self.mini_y_train)\n",
    "            self.loss = np.append(self.loss , self.c_loss)\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print(self.W)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "#         Z3 = self.activation3.forward(A3)\n",
    "#         A4 = self.FC4.forward(Z3)\n",
    "#         Z4 = self.activation4.forward(A4)\n",
    "#         A5 = self.FC5.forward(Z4)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        self.y_pred = np.argmax(Z3 , axis = 1)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def accuracy(self , X , t):\n",
    "        y_pred = self._predict(X)\n",
    "        return np.sum(y_pred == t) / float(X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題9】学習と推定\n",
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = ScratchDeepNeuralNetrowkClassifier(epochs = 10 , lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08900015 -0.08898247 -0.02015056 ... -0.0036665   0.10204279\n",
      "  -0.03095126]\n",
      " [ 0.00158414  0.0571258  -0.02655313 ...  0.01380231 -0.05624698\n",
      "  -0.00316739]\n",
      " [ 0.02441896 -0.03077423  0.01564676 ...  0.05406871 -0.07849301\n",
      "   0.13839742]\n",
      " ...\n",
      " [ 0.08122608  0.11368571  0.04495892 ... -0.00941898 -0.02449655\n",
      "  -0.09533314]\n",
      " [-0.07418259  0.00675893 -0.04129853 ...  0.11024035 -0.0374091\n",
      "   0.11809454]\n",
      " [-0.04050309  0.00492686  0.08520224 ...  0.08050452 -0.04943802\n",
      "  -0.09090019]]\n"
     ]
    }
   ],
   "source": [
    "dnn.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x136a0a9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1 , len(dnn.loss) + 1) , dnn.loss , label = \"loss\")\n",
    "# plt.plot(np.arange(1 , len(slr.val_loss) + 1) , slr.val_loss , label = \"test_loss\")\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(\"train_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.accuracy(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 6, ..., 5, 2, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn._predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.40073067, 1.13062797, 1.00491999, 0.93094726, 0.88092642,\n",
       "       0.84459979, 0.81669091, 0.79441059, 0.77603583, 0.76045839])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "\n",
    "    def __init__(self,epochs = 1,lr = 0.001 ,sigma = 0.01,n_nodes1= 400 , n_nodes2 = 300 ,n_nodes3=200 , n_nodes4=100, n_output = 10 , batch_size = 20, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_nodes3 = n_nodes3\n",
    "        self.n_nodes4 = n_nodes4\n",
    "        self.n_output = n_output\n",
    "        n_features = X_train.shape[1]\n",
    "        self.n_features = n_features\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.loss = []\n",
    "        self.epochs = epochs\n",
    "\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "   \n",
    "        Xavi = HeInitializer(self.n_nodes1 , self.n_nodes2)\n",
    "        self.W = Xavi.W()\n",
    "        self.B = Xavi.B()\n",
    "        optimizer = AdaGrad(self.lr , self.batch_size)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation1 = ReLU()\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation2 = ReLU()\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation3 = ReLU()\n",
    "        self.FC4 = FC(self.n_nodes3, self.n_nodes4, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation4 = ReLU()\n",
    "        self.FC5= FC(self.n_nodes4, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        self.activation5 = SoftmaxWithLoss()\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            self.get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "            for self.mini_X_train, self.mini_y_train in get_mini_batch:\n",
    "\n",
    "                A1 = self.FC1.forward(self.mini_X_train)\n",
    "                Z1 = self.activation1.forward(A1)\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                A4 = self.FC4.forward(Z3)\n",
    "                Z4 = self.activation4.forward(A4)\n",
    "                A5 = self.FC5.forward(Z4)\n",
    "                Z5 = self.activation5.forward(A5)\n",
    "                \n",
    "                dA5 = self.activation5.backward(Z5 , self.mini_y_train) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ4 = self.FC5.backward(dA5)                \n",
    "                dA4 = self.activation4.backward(dZ4)\n",
    "                dZ3 = self.FC4.backward(dA4)                \n",
    "                dA3 = self.activation3.backward(dZ3)\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "#                 dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "                self.c_loss = self.activation5.Loss(Z5 , self.mini_y_train)\n",
    "            self.loss = np.append(self.loss , self.c_loss)\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "\n",
    "    def _predict(self, X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        A4 = self.FC4.forward(Z3)\n",
    "        Z4 = self.activation4.forward(A4)\n",
    "        A5 = self.FC5.forward(Z4)\n",
    "        Z5 = self.activation5.forward(A5)\n",
    "        self.y_pred = np.argmax(Z5 , axis = 1)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def accuracy(self , X , t):\n",
    "        y_pred = self._predict(X)\n",
    "        return np.sum(y_pred == t) / float(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = ScratchDeepNeuralNetrowkClassifier(epochs = 10 , lr = 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dnn.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 5, ..., 5, 2, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn._predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x136856898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1 , len(dnn.loss) + 1) , dnn.loss , label = \"loss\")\n",
    "# plt.plot(np.arange(1 , len(slr.val_loss) + 1) , slr.val_loss , label = \"test_loss\")\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(\"train_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.accuracy(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
