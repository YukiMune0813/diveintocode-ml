{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自然言語処理（NLP, Natural Language Processing） とは人間が普段使っている 自然言語 をコンピュータに処理させる技術のことです。ここではその中でも、機械学習の入力として自然言語を用いることを考えていきます。\n",
    "\n",
    "\n",
    "多くの機械学習手法は 数値データ（量的変数） の入力を前提にしていますので、自然言語の テキストデータ を数値データに変換する必要があります。これを 自然言語のベクトル化 と呼びます。ベクトル化の際にテキストデータの特徴をうまく捉えられるよう、様々な手法が考えられてきていますので、このSprintではそれらを学びます。\n",
    "\n",
    "\n",
    "非構造化データ\n",
    "データの分類として、表に数値がまとめられたようなコンピュータが扱いやすい形を 構造化データ 、人間が扱いやすい画像・動画・テキスト・音声などを 非構造化データ と呼ぶことがあります。自然言語のベクトル化は、非構造化データを構造化データに変換する工程と言えます。同じ非構造化データでも、画像に対してはディープラーニングを用いる場合この変換作業はあまり必要がありませんでしたが、テキストにおいてはこれをどう行うかが重要です。\n",
    "\n",
    "\n",
    "自然言語処理により何ができるか\n",
    "機械学習の入力や出力に自然言語のテキストを用いることで様々なことができます。入力も出力もテキストである例としては 機械翻訳 があげられ、実用化されています。入力は画像で出力がテキストである 画像キャプション生成 やその逆の文章からの画像生成も研究が進んでいます。\n",
    "\n",
    "\n",
    "しかし、出力をテキストや画像のような非構造化データとすることは難易度が高いです。比較的簡単にできることとしては、入力をテキスト、出力をカテゴリーとする テキスト分類 です。\n",
    "\n",
    "\n",
    "アヤメやタイタニック、手書き数字のような定番の存在として、IMDB映画レビューデータセット の感情分析があります。レビューの文書が映画に対して肯定的か否定的かを2値分類します。文書ごとの肯定・否定はラベルが与えられています。このSprintではこれを使っていきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-21 16:39:19--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "ai.stanford.edu (ai.stanford.edu) をDNSに問いあわせています... 171.64.68.10\n",
      "ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80 に接続しています... 接続しました。\n",
      "HTTP による接続要求を送信しました、応答を待っています... 200 OK\n",
      "長さ: 84125825 (80M) [application/x-gzip]\n",
      "`aclImdb_v1.tar.gz.1' に保存中\n",
      "\n",
      "aclImdb_v1.tar.gz.1 100%[===================>]  80.23M  4.63MB/s 時間 18s        \n",
      "\n",
      "2020-04-21 16:39:37 (4.58 MB/s) - `aclImdb_v1.tar.gz.1' へ保存完了 [84125825/84125825]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#IMDB映画レビューデータセットを準備します。\n",
    "!wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    \n",
    "# 解凍\n",
    "!tar zxf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m Sprint_24\u001b[m\u001b[m/\r\n",
      "20191022VCS_Github_DIC.pdf\r\n",
      "20200123_EDA_example.ipynb\r\n",
      "Breast.ipynb\r\n",
      "CNN.ipynb\r\n",
      "CNN2.ipynb\r\n",
      "Classifier Flow(Home Credit)_2.ipynb\r\n",
      "Comprehensive data exploration with Python | Kaggle.pdf\r\n",
      "\u001b[34mDICスライド\u001b[m\u001b[m/\r\n",
      "DeepNN.ipynb\r\n",
      "GAN.ipynb\r\n",
      "Githubフローハンズオン.pdf\r\n",
      "Home Credit Default Risk Extensive EDA | Kaggle.webloc\r\n",
      "\u001b[31mHomeCredit_columns_description.csv\u001b[m\u001b[m*\r\n",
      "Install.ipynb\r\n",
      "Iris.csv\r\n",
      "Keras.ipynb\r\n",
      "MNIST.ipynb\r\n",
      "Mr.Shibata_sprint2.ipynb\r\n",
      "NN.ipynb\r\n",
      "Pandas Graph.ipynb\r\n",
      "Python for DATA ANALYSIS.ipynb\r\n",
      "README.md\r\n",
      "SVM.ipynb\r\n",
      "SVM基本.ipynb\r\n",
      "Scratch1_HomeCredit.ipynb\r\n",
      "Sprint0_scratch.ipynb\r\n",
      "Sprint10_CNN.ipynb\r\n",
      "Sprint11_CNN2.ipynb\r\n",
      "Sprint12_tensorflow.ipynb\r\n",
      "Sprint13_Keras.ipynb\r\n",
      "Sprint13_Tensorflow入門 (1).ipynb\r\n",
      "Sprint14_Reading.ipynb\r\n",
      "Sprint16_colab版の準備（受講生用） (1).ipynb\r\n",
      "Sprint17_make_dataset.ipynb\r\n",
      "Sprint18 segmentation.ipynb\r\n",
      "Sprint18_colab版の準備（受講生用）_ipynb_のコピー.ipynb\r\n",
      "Sprint18_セグメンテーション1.pdf\r\n",
      "\u001b[34mSprint19\u001b[m\u001b[m/\r\n",
      "Sprint19.ipynb\r\n",
      "Sprint1_ML_Flow.ipynb\r\n",
      "Sprint20_NLP.ipynb\r\n",
      "Sprint22 RNN.ipynb\r\n",
      "Sprint22_gateRNN.ipynb\r\n",
      "Sprint23_seq2seq.ipynb\r\n",
      "Sprint2_linear_regression.ipynb\r\n",
      "Sprint3_logistic_regression.ipynb\r\n",
      "Sprint4_SVM-2-Copy1.ipynb\r\n",
      "Sprint4_SVM-2.ipynb\r\n",
      "Sprint4_SVM.ipynb\r\n",
      "Sprint5_DecisionTree.ipynb\r\n",
      "Sprint6_K-means.ipynb\r\n",
      "Sprint8_NN.ipynb\r\n",
      "Sprint9_DNN.ipynb\r\n",
      "Sprint_2.4 ML.ipynb\r\n",
      "Sprint_24.textClipping\r\n",
      "Sprint_7_Ensemble.ipynb\r\n",
      "StyleGAN2 Distillation for Feed-forward Image Manipulation.pdf\r\n",
      "Untitled.ipynb\r\n",
      "Untitled1.ipynb\r\n",
      "Untitled2.ipynb\r\n",
      "Untitled3.ipynb\r\n",
      "Untitled4.ipynb\r\n",
      "Untitled5.ipynb\r\n",
      "Untitled6.ipynb\r\n",
      "Untitled7.ipynb\r\n",
      "Untitled8.ipynb\r\n",
      "Untitled9.ipynb\r\n",
      "Week 1 栗まんじゅう問題.ipynb\r\n",
      "Week 1 曽呂利新左衛門問題.ipynb\r\n",
      "Week1.富士山問題.ipynb\r\n",
      "Week1_python.ipynb\r\n",
      "Week2_2_dummy.ipynb\r\n",
      "Week2_3_matrixproduct.ipynb\r\n",
      "Week2_class1_2Darray.ipynb\r\n",
      "Week2_class2_Mt.Fuji.ipynb\r\n",
      "Week2komugitochess.ipynb\r\n",
      "Week3-classwork1_2.ipynb\r\n",
      "Week3_1_iris.ipynb\r\n",
      "Week3_2_house.ipynb\r\n",
      "Week3_classwork1.ipynb\r\n",
      "Week4.ipynb\r\n",
      "Week4_1_iris.ipynb\r\n",
      "Week4_2_house.ipynb\r\n",
      "Week4_3_object.ipynb\r\n",
      "Wholesale customers data.csv\r\n",
      "YM_example_answer_week2_work1.ipynb\r\n",
      "_about.txt\r\n",
      "\u001b[34maclImdb\u001b[m\u001b[m/\r\n",
      "aclImdb_v1.tar.gz\r\n",
      "aclImdb_v1.tar.gz.1\r\n",
      "\u001b[31mapplication_test.csv\u001b[m\u001b[m*\r\n",
      "application_test.csv.zip\r\n",
      "\u001b[31mapplication_train.csv\u001b[m\u001b[m*\r\n",
      "\u001b[34mcache\u001b[m\u001b[m/\r\n",
      "dog_3.jpeg\r\n",
      "dotbZRNGpe.csv\r\n",
      "example_answer_week1_work1.ipynb\r\n",
      "example_answer_week2_work1 (1).ipynb\r\n",
      "example_answer_week2_work2.ipynb\r\n",
      "example_answer_week2_work3.ipynb\r\n",
      "example_answer_week3_work1.ipynb\r\n",
      "example_answer_week3_work2.ipynb\r\n",
      "example_answer_week4_work1.ipynb\r\n",
      "example_answer_week4_work2.ipynb\r\n",
      "example_answer_week4_work3.ipynb\r\n",
      "fra-eng.zip\r\n",
      "fra.txt\r\n",
      "gaiyo.pdf\r\n",
      "\u001b[31mgogo.jpg\u001b[m\u001b[m*\r\n",
      "gs_result.csv\r\n",
      "\u001b[34mhome-credit-default-risk\u001b[m\u001b[m/\r\n",
      "\u001b[34mimage\u001b[m\u001b[m/\r\n",
      "\u001b[34mimage_out\u001b[m\u001b[m/\r\n",
      "kaggle_kernel (Regression).ipynb\r\n",
      "logistic.ipynb\r\n",
      "mtfuji_data.csv\r\n",
      "np piazza グラフ.ipynb\r\n",
      "petbottle_reconaize.ipynb\r\n",
      "\u001b[31mprevious_application.csv\u001b[m\u001b[m*\r\n",
      "s2s.h5\r\n",
      "sample.csv\r\n",
      "\u001b[31msample_submission.csv\u001b[m\u001b[m*\r\n",
      "sprint1-work1.ipynb\r\n",
      "sprint17.zip\r\n",
      "sprint4_logi.ipynb\r\n",
      "start-here-a-gentle-introduction.ipynb\r\n",
      "submit_200204.csv\r\n",
      "submit_200205.csv\r\n",
      "summer2winter_yosemite.pth\r\n",
      "test.zip\r\n",
      "titanic-data-science-solutions.ipynb\r\n",
      "train.csv\r\n",
      "train.textClipping\r\n",
      "\u001b[34mtraining\u001b[m\u001b[m/\r\n",
      "week3_work1_Home Credit Default Risk.ipynb\r\n",
      "week4introduction-to-manual-feature-engineering.ipynb\r\n",
      "論文.ipynb\r\n",
      "決定木.ipynb\r\n",
      "紙を折る.ipynb\r\n",
      "線形回帰.ipynb\r\n",
      "クラスタリング.ipynb\r\n",
      "交差検証　基本.ipynb\r\n",
      "アンサンブル学習.ipynb\r\n",
      "教師あり学習基本.ipynb\r\n",
      "\u001b[34mグループワーク\u001b[m\u001b[m/\r\n",
      "\u001b[34m卒業プロジェクト\u001b[m\u001b[m/\r\n",
      "ロジスティック回帰とSVM.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "x_train , y_train = train_review.data , train_review.target\n",
    "\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test , y_test = test_review.data , test_review.target\n",
    "\n",
    "#ラベルの0,1と意味の対応の表示\n",
    "print(train_review.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_review.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aclImdb/train/unsupはラベル無しのため削除\n",
    "!rm -rf aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#train_review\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットについて\n",
    "中身を見てみると、英語の文章が入っていることが分かります\n",
    "4点以下を否定的、7点以下を肯定的なレビューとして2値のラベル付けしており、これにより感情の分類を行います。5,6点の中立的なレビューはデータセットに含んでいません。また、ラベルは訓練用・テスト用それぞれで均一に入っています。詳細はダウンロードしたREADMEを確認してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n"
     ]
    }
   ],
   "source": [
    "print(\"x : {}\".format(x_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純ながら効果的な方法として BoW (Bag of Words) があります。これは、サンプルごとに単語などの 登場回数 を数えたものをベクトルとする方法です。単語をカテゴリとして捉え one-hot表現 していることになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_dataset = \\\n",
    "  [\"This movie is very good.\",\n",
    "  \"This film is a good\",\n",
    "  \"Very bad. Very, very bad.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>bad</th>\n",
       "      <th>film</th>\n",
       "      <th>good</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  bad  film  good  is  movie  this  very\n",
       "0  0    0     0     1   1      1     1     1\n",
       "1  1    0     1     1   1      0     1     0\n",
       "2  0    2     0     0   0      0     0     3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#CountVectorizer?単語の出現頻度を数える\n",
    "#BoWは厳密には単語を数えているのではなく、 トークン（token） として定めた固まりを数えます\n",
    "vectorizer = CountVectorizer(token_pattern=r'(?u)\\b\\w+\\b')\n",
    "\n",
    "bow = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "# DataFrameにまとめる\n",
    "df = pd.DataFrame(bow, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "形態素解析\n",
    "英語などの多くの言語では空白という分かりやすい基準でトークン化が行えますが、日本語ではそれが行えません。\n",
    "\n",
    "\n",
    "日本語では名詞や助詞、動詞のように異なる 品詞 で分けられる単位で 分かち書き することになります。例えば「私はプログラミングを学びます」という日本語の文は「私/は/プログラミング/を/学び/ます」という風になります。\n",
    "\n",
    "\n",
    "これには MeCab や Janome のような形態素解析ツールを用います。Pythonから利用することも可能です。MeCabをウェブ上で簡単に利用できる\n",
    "Web茶まめ\n",
    "というサービスも国立国語研究所が提供しています。\n",
    "\n",
    "\n",
    "自然言語では新しい言葉も日々生まれますので、それにどれだけ対応できるかも大切です。MeCab用の毎週更新される辞書として mecab-ipadic-NEologd がオープンソースで存在しています。\n",
    "\n",
    "https://github.com/neologd/mecab-ipadic-neologd/blob/master/README.ja.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-gram\n",
    "上のBoWの例では1つの単語（トークン）毎の登場回数を数えましたが、これでは語順は全く考慮されていません。\n",
    "\n",
    "\n",
    "考慮するために、隣あう単語同士をまとめて扱う n-gram という考え方を適用することがあります。2つの単語をまとめる場合は 2-gram (bigram) と呼び、次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a good</th>\n",
       "      <th>bad very</th>\n",
       "      <th>film is</th>\n",
       "      <th>is a</th>\n",
       "      <th>is very</th>\n",
       "      <th>movie is</th>\n",
       "      <th>this film</th>\n",
       "      <th>this movie</th>\n",
       "      <th>very bad</th>\n",
       "      <th>very good</th>\n",
       "      <th>very very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a good  bad very  film is  is a  is very  movie is  this film  this movie  \\\n",
       "0       0         0        0     0        1         1          0           1   \n",
       "1       1         0        1     1        0         0          1           0   \n",
       "2       0         1        0     0        0         0          0           0   \n",
       "\n",
       "   very bad  very good  very very  \n",
       "0         0          1          0  \n",
       "1         0          0          0  \n",
       "2         2          0          1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ngram_rangeで利用するn-gramの範囲を指定する\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2), token_pattern=r'(?u)\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題1】BoWのスクラッチ実装   \n",
    "以下の3文のBoWを求められるプログラムをscikit-learnを使わずに作成してください。1-gramと2-gramで計算してください。   \n",
    "This movie is SOOOO funny!!!  \n",
    "What a movie! I never  \n",
    "best movie ever!!!!! this movie\n",
    "\n",
    "カラムの作成\n",
    "①クリーニング(正規表現、文字であるものを抽出する)、大文字小文字 \n",
    "②分割:split(\" \")\n",
    "③pd.DataFrame\n",
    "\n",
    "カラム名と文章の比較\n",
    "①出現回数のカウント\n",
    "②カラムと切り出された文字列の照合:切り出す\n",
    "③一致したらカラムに足す\n",
    "forとif\n",
    "④"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This movie is SOOOO funny!!! ', 'What a movie! I never', 'best movie ever!!!!! this movie']\n"
     ]
    }
   ],
   "source": [
    "test_dataset= \\\n",
    "[\"This movie is SOOOO funny!!! \" ,\n",
    "\"What a movie! I never\",\n",
    "\"best movie ever!!!!! this movie\"]\n",
    "\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://robonchu.hatenablog.com/entry/2017/11/20/183403\n",
    "mini_dataset = [\"This movie is SOOOO funny!!!\",\n",
    "                        \"What a movie! I never\" , \n",
    "                        \"best movie ever!!!!! this movie\"]\n",
    "\n",
    "def scratch_BOW(dataset , n=1):\n",
    "    df = pd.DataFrame(index=range(len(dataset)))\n",
    "    for i , data in enumerate(dataset):\n",
    "        word_list0 = make_word_list(data)\n",
    "        word_list = [\" \".join(word_list0[i : i+n])for i in range(len(word_list0) - (n-1))]\n",
    "        for word in word_list:\n",
    "            if word not in df.columns:\n",
    "                df[word] = 0\n",
    "            df.loc[i , word] += 1\n",
    "    df_s = df.sort_index(axis=1)\n",
    "    return df_s\n",
    "\n",
    "def make_word_list(sentence):\n",
    "    sentence = sentence.replace(\",\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace('\"', '').replace(\"<br />\", \"\").replace(\"/\", \" and \").lower()\n",
    "    return sentence.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>i</th>\n",
       "      <th>is</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  best  ever  funny  i  is  movie  never  soooo  this  what\n",
       "0  0     0     0      1  0   1      1      0      1     1     0\n",
       "1  1     0     0      0  1   0      1      1      0     0     1\n",
       "2  0     1     1      0  0   0      2      0      0     1     0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = scratch_BOW(mini_dataset)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a movie</th>\n",
       "      <th>best movie</th>\n",
       "      <th>ever this</th>\n",
       "      <th>i never</th>\n",
       "      <th>is soooo</th>\n",
       "      <th>movie ever</th>\n",
       "      <th>movie i</th>\n",
       "      <th>movie is</th>\n",
       "      <th>soooo funny</th>\n",
       "      <th>this movie</th>\n",
       "      <th>what a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a movie  best movie  ever this  i never  is soooo  movie ever  movie i  \\\n",
       "0        0           0          0        0         1           0        0   \n",
       "1        1           0          0        1         0           0        1   \n",
       "2        0           1          1        0         0           1        0   \n",
       "\n",
       "   movie is  soooo funny  this movie  what a  \n",
       "0         1            1           1       0  \n",
       "1         0            0           0       1  \n",
       "2         0            0           1       0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = scratch_BOW(mini_dataset , n=2)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 7, 'movie': 4, 'is': 3, 'soooo': 6, 'funny': 2, 'what': 8, 'never': 5, 'best': 0, 'ever': 1}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array([\"This movie is SOOOO funny !!!\",\n",
    "                        \"What a movie ! I never\" , \n",
    "                        \"best movie ever !!!!! this movie\"])\n",
    "bag = count.fit_transform(docs)\n",
    "\n",
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 0 1 1 0]\n",
      " [0 0 0 0 1 1 0 0 1]\n",
      " [1 1 0 0 2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.TF-IDF\n",
    "BoWの発展的手法として TF-IDF もよく使われます。これは Term Frequency (TF) と Inverse Document Frequency (IDF) という2つの指標の組み合わせです。\n",
    "\n",
    "IDFはそのトークンがデータセット内で珍しいほど値が大きくなる指標です。\n",
    "\n",
    "サンプル数 N をIMDB映画レビューデータセットの訓練用データに合わせ25000として、トークンが出現するサンプル数 d f ( t ) を変化させたグラフを確認してみると、次のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119ab9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 25000\n",
    "idf = np.log(n_samples / np.arange(1 , n_samples))\n",
    "plt.title(\"IDF\")\n",
    "plt.xlabel(\"df(t)\")\n",
    "plt.ylabel(\"IDF\")\n",
    "plt.plot(idf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ストップワード\n",
    "あまりにも頻繁に登場するトークンは、値を小さくするだけでなく、取り除くという前処理を加えることもあります。取り除くもののことを ストップワード と呼びます。既存のストップワード一覧を利用したり、しきい値によって求めたりします。\n",
    "\n",
    "scikit-learnのCountVectorizerでは引数stop_wordsにリストで指定することで処理を行なってくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>funny</th>\n",
       "      <th>i</th>\n",
       "      <th>movie</th>\n",
       "      <th>never</th>\n",
       "      <th>soooo</th>\n",
       "      <th>this</th>\n",
       "      <th>what</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  best  ever  funny  i  movie  never  soooo  this  what\n",
       "0  0     0     0      1  0      1      0      1     1     0\n",
       "1  1     0     0      0  1      1      1      0     0     1\n",
       "2  0     1     1      0  0      2      0      0     1     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = [\"is\"] , token_pattern=r'\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train , columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代表的な既存のストップワード一覧としては、NLTK という自然言語処理のライブラリのものがあげられます。あるデータセットにおいては特別重要な意味を持つ単語が一覧に含まれている可能性もあるため、使用する際は中身を確認することが望ましいです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "stop word : ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "stop_words = nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(\"stop word : {}\".format(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "逆に、登場回数が特に少ないトークンも取り除くことが多いです。全てのトークンを用いるとベクトルの次元数が著しく大きくなってしまい計算コストが高まるためです。\n",
    "\n",
    "scikit-learnのCountVectorizerでは引数max_featuresに最大の語彙数を指定することで処理を行なってくれます。以下の例では出現数が多い順に5個でベクトル化しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>best</th>\n",
       "      <th>ever</th>\n",
       "      <th>movie</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  best  ever  movie  this\n",
       "0  0     0     0      1     1\n",
       "1  1     0     0      1     0\n",
       "2  0     1     1      2     1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b' , max_features = 5)\n",
    "bow_train = (vectorizer.fit_transform(mini_dataset)).toarray()\n",
    "df = pd.DataFrame(bow_train , columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題2】TF-IDFの計算  \n",
    "IMDB映画レビューデータセットをTF-IDFによりベクトル化してください。NLTKのストップワードを利用し、最大の語彙数は5000程度に設定してください。テキストクリーニングやステミングなどの前処理はこの問題では要求しません。\n",
    "\n",
    "\n",
    "TF-IDFの計算にはscikit-learnの以下のどちらかのクラスを使用してください。\n",
    "\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfVectorizer — scikit-learn 0.21.3 documentation\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfTransformer — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "なお、scikit-learnでは標準的な式とは異なる式が採用されています。\n",
    "\n",
    "\n",
    "また、デフォルトではnorm=\"l2\"の引数が設定されており、各サンプルにL2正規化が行われます。norm=Noneとすることで正規化は行われなくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "#\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "#dataを抽出してx_trainに格納、targetを抽出してy_trainに格納\n",
    "x_train, y_train = train_review.data, train_review.target\n",
    "\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test, y_test = test_review.data, test_review.target\n",
    "# ラベルの0,1と意味の対応の表示\n",
    "print(train_review.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>13th</th>\n",
       "      <th>...</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>z</th>\n",
       "      <th>zero</th>\n",
       "      <th>zizek</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24971</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24973</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24975</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24977</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24981</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24989</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  00  000  1  10  100  11  12  13  13th  ...   york  young  younger  \\\n",
       "0      0   0    0  0   0    0   0   0   0     0  ...      0      2        0   \n",
       "1      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "2      0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "3      0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "4      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "5      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "6      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "7      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "8      0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "9      0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "10     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "11     0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "12     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "13     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "14     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "15     0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "16     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "17     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "18     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "19     0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "20     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "21     0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "22     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "23     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "25     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "26     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "27     0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "28     0   0    0  0   0    0   0   2   0     0  ...      0      0        0   \n",
       "29     0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "...   ..  ..  ... ..  ..  ...  ..  ..  ..   ...  ...    ...    ...      ...   \n",
       "24970  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24971  0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "24972  0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "24973  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24974  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24975  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24976  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24977  0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "24978  0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "24979  0   0    0  0   0    0   0   0   0     0  ...      0      1        0   \n",
       "24980  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24981  0   0    0  0   1    0   0   0   0     0  ...      0      1        0   \n",
       "24982  0   0    0  0   0    0   0   0   0     0  ...      0      4        0   \n",
       "24983  0   0    0  0   0    0   0   0   0     0  ...      0      2        0   \n",
       "24984  0   0    0  1   0    0   0   0   0     0  ...      0      0        0   \n",
       "24985  0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "24986  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24987  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24988  0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "24989  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24990  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24991  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24992  0   0    0  0   0    0   1   0   0     0  ...      0      0        0   \n",
       "24993  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24994  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24995  0   0    0  0   0    1   0   0   0     0  ...      2      0        0   \n",
       "24996  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "24997  0   0    0  0   1    0   0   0   0     0  ...      0      0        0   \n",
       "24998  0   0    0  1   0    0   0   0   0     0  ...      0      0        0   \n",
       "24999  0   0    0  0   0    0   0   0   0     0  ...      0      0        0   \n",
       "\n",
       "       youth  z  zero  zizek  zombie  zombies  zone  \n",
       "0          0  0     1      0       0        0     0  \n",
       "1          0  0     0      0       0        0     0  \n",
       "2          0  0     0      0       0        0     0  \n",
       "3          0  0     0      0       0        0     0  \n",
       "4          0  0     0      0       0        0     0  \n",
       "5          0  0     0      0       0        0     0  \n",
       "6          0  0     0      0       0        0     0  \n",
       "7          0  0     0      0       0        0     0  \n",
       "8          0  0     0      0       0        0     0  \n",
       "9          0  0     0      0       0        0     0  \n",
       "10         0  0     0      0       0        0     0  \n",
       "11         0  0     0      0       0        0     0  \n",
       "12         0  0     0      0       0        0     0  \n",
       "13         0  0     0      0       0        0     0  \n",
       "14         0  0     0      0       0        0     0  \n",
       "15         0  0     0      0       0        0     0  \n",
       "16         0  0     0      0       0        0     0  \n",
       "17         0  0     0      0       0        1     0  \n",
       "18         0  0     0      0       0        0     0  \n",
       "19         0  0     0      0       0        0     0  \n",
       "20         0  0     0      0       0        0     0  \n",
       "21         2  0     0      0       0        0     0  \n",
       "22         0  0     0      0       0        0     0  \n",
       "23         0  0     0      0       0        0     0  \n",
       "24         0  0     0      0       0        0     0  \n",
       "25         0  0     0      0       0        1     0  \n",
       "26         0  0     0      0       0        0     0  \n",
       "27         0  0     1      0       0        0     0  \n",
       "28         0  0     0      0       0        0     0  \n",
       "29         0  0     0      0       0        0     0  \n",
       "...      ... ..   ...    ...     ...      ...   ...  \n",
       "24970      0  0     0      0       0        0     0  \n",
       "24971      0  0     0      0       0        0     0  \n",
       "24972      0  0     0      0       0        0     0  \n",
       "24973      0  0     0      0       0        0     0  \n",
       "24974      0  0     0      0       0        0     0  \n",
       "24975      0  0     0      0       0        0     0  \n",
       "24976      0  0     0      0       0        0     0  \n",
       "24977      0  0     0      0       0        0     0  \n",
       "24978      0  0     0      0       0        0     0  \n",
       "24979      0  0     0      0       0        0     0  \n",
       "24980      0  0     2      0       0        0     0  \n",
       "24981      0  0     0      0       0        0     0  \n",
       "24982      0  0     0      0       0        0     0  \n",
       "24983      0  0     0      0       0        0     0  \n",
       "24984      0  0     0      0       0        0     0  \n",
       "24985      0  0     0      0       0        0     0  \n",
       "24986      0  0     0      0       0        0     0  \n",
       "24987      0  0     0      0       0        0     0  \n",
       "24988      0  0     0      0       0        0     0  \n",
       "24989      0  0     0      0       0        0     0  \n",
       "24990      0  0     0      0       0        0     0  \n",
       "24991      0  0     0      0       0        0     0  \n",
       "24992      0  0     0      0       0        0     0  \n",
       "24993      0  0     0      0       0        0     0  \n",
       "24994      0  0     0      0       0        0     0  \n",
       "24995      0  0     0      0       0        0     0  \n",
       "24996      0  0     0      0       0        0     0  \n",
       "24997      0  0     0      0       0        0     0  \n",
       "24998      0  0     0      0       0        0     0  \n",
       "24999      0  0     0      0       0        0     0  \n",
       "\n",
       "[25000 rows x 5000 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words, token_pattern=r'\\b\\w+\\b', max_features = 5000)\n",
    "bow_train = (vectorizer.fit_transform(x_train)).toarray()\n",
    "df = pd.DataFrame(bow_train, columns=vectorizer.get_feature_names())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>actors</th>\n",
       "      <th>almost</th>\n",
       "      <th>anything</th>\n",
       "      <th>better</th>\n",
       "      <th>beyond</th>\n",
       "      <th>bizarre</th>\n",
       "      <th>boys</th>\n",
       "      <th>br</th>\n",
       "      <th>captures</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>two</th>\n",
       "      <th>via</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actions    actors    almost  anything    better    beyond   bizarre  \\\n",
       "0  0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "\n",
       "       boys        br  captures    ...     terrible     think      time  \\\n",
       "0  0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "\n",
       "        two       via  withdraw     world     would     young      zero  \n",
       "0  0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = \n",
    "                             stop_words ,ngram_range=(1,1), token_pattern=r'\\b\\w+\\b' , max_features = 5000)\n",
    "bow_train = (vectorizer.fit_transform(x_train[0:1])).toarray()\n",
    "df = pd.DataFrame(bow_train , columns=vectorizer.get_feature_names())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actions</th>\n",
       "      <th>actors</th>\n",
       "      <th>almost</th>\n",
       "      <th>anything</th>\n",
       "      <th>better</th>\n",
       "      <th>beyond</th>\n",
       "      <th>bizarre</th>\n",
       "      <th>boys</th>\n",
       "      <th>br</th>\n",
       "      <th>captures</th>\n",
       "      <th>...</th>\n",
       "      <th>terrible</th>\n",
       "      <th>think</th>\n",
       "      <th>time</th>\n",
       "      <th>two</th>\n",
       "      <th>via</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>young</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.379663</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.284747</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.094916</td>\n",
       "      <td>0.189832</td>\n",
       "      <td>0.094916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actions    actors    almost  anything    better    beyond   bizarre  \\\n",
       "count  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "mean   0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "std         NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "min    0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "25%    0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "50%    0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "75%    0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "max    0.094916  0.094916  0.094916  0.094916  0.189832  0.094916  0.094916   \n",
       "\n",
       "           boys        br  captures    ...     terrible     think      time  \\\n",
       "count  1.000000  1.000000  1.000000    ...     1.000000  1.000000  1.000000   \n",
       "mean   0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "std         NaN       NaN       NaN    ...          NaN       NaN       NaN   \n",
       "min    0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "25%    0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "50%    0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "75%    0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "max    0.094916  0.379663  0.094916    ...     0.094916  0.189832  0.094916   \n",
       "\n",
       "            two       via  withdraw     world     would     young      zero  \n",
       "count  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  1.000000  \n",
       "mean   0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "std         NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
       "min    0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "25%    0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "50%    0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "75%    0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "max    0.284747  0.189832  0.094916  0.094916  0.094916  0.189832  0.094916  \n",
       "\n",
       "[8 rows x 61 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0949158 0.0949158 0.0949158 0.0949158 0.1898316 0.0949158 0.0949158\n",
      "  0.0949158 0.3796632 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158\n",
      "  0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158\n",
      "  0.0949158 0.1898316 0.1898316 0.0949158 0.0949158 0.0949158 0.0949158\n",
      "  0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158\n",
      "  0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.1898316 0.0949158\n",
      "  0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158 0.0949158\n",
      "  0.1898316 0.1898316 0.0949158 0.1898316 0.0949158 0.2847474 0.1898316\n",
      "  0.0949158 0.0949158 0.0949158 0.1898316 0.0949158]]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\n",
    "                            stop_words, ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', max_features = 5000)\n",
    "#ベクトル化\n",
    "bow_train = vectorizer.fit_transform(x_train[0:1]).toarray()\n",
    "print(bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\n",
    "                            stop_words, ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', max_features = 5000)\n",
    "#ベクトル化\n",
    "bow_train = vectorizer.fit_transform(x_train).toarray()\n",
    "print(bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "vectorizer = TfidfVectorizer(stop_words=\n",
    "                            stop_words, ngram_range=(1, 1), token_pattern=r'\\b\\w+\\b', max_features = 5000)\n",
    "#ベクトル化\n",
    "bow_test = vectorizer.fit_transform(x_test).toarray()\n",
    "print(bow_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題3】TF-IDFを用いた学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(bow_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91908"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(bow_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53536"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(bow_test , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題4】TF-IDFのスクラッチ実装\n",
    "以下の3文のTF-IDFを求められるプログラムをscikit-learnを使わずに作成してください。標準的な式と、scikit-learnの採用している式の2種類を作成してください。正規化は不要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TF_IDF():\n",
    "    \n",
    "    def __init__(self , corpus):\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def tf(self):\n",
    "        l = []\n",
    "        c = []\n",
    "        \n",
    "        #corpusの各テキストを単語毎に分割\n",
    "        for text in self.corpus:\n",
    "            c += re.findall(r'\\b\\w+\\b' , text)\n",
    "        \n",
    "        #抽出した単語の重複を削除\n",
    "        c = list(set(c))\n",
    "        \n",
    "        #各テキスト毎の単語出現回数をカウントし、該当テキストの総単語数で割る\n",
    "        for text in self.corpus:\n",
    "            x = re.findall(r'\\b\\w+\\b' , text)\n",
    "            l.append([x.count(i) / len(x) for i in c])\n",
    "        return np.array(l)\n",
    "    \n",
    "    def idf(self):\n",
    "        terms = []\n",
    "        \n",
    "        for text in self.corpus:\n",
    "            terms += re.findall(r'\\b\\w+\\b' , text)\n",
    "            \n",
    "        terms = list(set(terms))\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        for term in terms:\n",
    "            c = 0\n",
    "        \n",
    "            for text in self.corpus:\n",
    "                word_list = re.findall(r'\\b\\w+\\b' , text)\n",
    "                #該当テキスト内に含まれている単語であれば、１カウントする\n",
    "                #重複カウントを防ぐために論理演算子は『in』を用いる\n",
    "                #文章の繋がりで、単語ではないものを単語としてカウントしないように上記でリスト化している\n",
    "                if term in word_list:\n",
    "                    c += 1\n",
    "            \n",
    "            l.append(np.log(len(self.corpus) / c ))\n",
    "            \n",
    "        return np.array(l)\n",
    "    \n",
    "    def l2(self , x):\n",
    "        #l2ノルムで正規化する（単位ベクトル化）\n",
    "        l2 = x / np.sqrt(np.sum(x**2))\n",
    "        \n",
    "        return l2\n",
    "    \n",
    "    def tf_idf(self):\n",
    "        x = self.tf() * self.idf()\n",
    "        #各行にl2ノルムの正規化を適用\n",
    "        return np.array([self.l2(a) for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = [\"This movie is SOOOO funny!!!\",\n",
    "                    \"What a movie! I never\",\n",
    "                    \"best movie ever!!!!! this movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TF_IDF(mini_data)\n",
    "tf_idf = tf.tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "2.0\n",
      "1.7320508075688772\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(tf_idf[0]))\n",
    "print(np.sum(tf_idf[1]))\n",
    "print(np.sum(tf_idf[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1956355375164818\n",
      "2.201328677102573\n",
      "1.977388147087266\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_data)).toarray()\n",
    "df = pd.DataFrame(bow_train , columns=vectorizer.get_feature_names())\n",
    "print(np.sum(bow_train[0]))\n",
    "print(np.sum(bow_train[1]))\n",
    "print(np.sum(bow_train[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TF_IDF2():\n",
    "    \n",
    "    def __init__(self , corpus):\n",
    "        self.corpus = corpus\n",
    "        \n",
    "    def tf(self):\n",
    "        l = []\n",
    "        c = []\n",
    "        \n",
    "        #corpusの各テキストを単語毎に分割\n",
    "        for text in self.corpus:\n",
    "            c += re.findall(r'\\b\\w+\\b' , text)\n",
    "        \n",
    "        #抽出した単語の重複を削除\n",
    "        c = list(set(c))\n",
    "        \n",
    "        #各テキスト毎の単語出現回数をカウントし、該当テキストの総単語数で割る\n",
    "        for text in self.corpus:\n",
    "            x = re.findall(r'\\b\\w+\\b' , text)\n",
    "            l.append([x.count(i) / len(x) for i in c])\n",
    "        return np.array(l)\n",
    "    \n",
    "    def idf(self):\n",
    "        terms = []\n",
    "        \n",
    "        for text in self.corpus:\n",
    "            terms += re.findall(r'\\b\\w+\\b' , text)\n",
    "            \n",
    "        terms = list(set(terms))\n",
    "        \n",
    "        l = []\n",
    "        \n",
    "        for term in terms:\n",
    "            c = 0\n",
    "        \n",
    "            for text in self.corpus:\n",
    "                word_list = re.findall(r'\\b\\w+\\b' , text)\n",
    "                #該当テキスト内に含まれている単語であれば、１カウントする\n",
    "                #重複カウントを防ぐために論理演算子は『in』を用いる\n",
    "                #文章の繋がりで、単語ではないものを単語としてカウントしないように上記でリスト化している\n",
    "                if term in word_list:\n",
    "                    c += 1\n",
    "            \n",
    "            #各単語IDFを計算。sklearnの計算と合わせるため、分母分子に１を足す\n",
    "            #更にその計算結果にも１を足す\n",
    "            l.append(np.log((1 + len(self.corpus)) / (c + 1)) + 1)\n",
    "            \n",
    "        return np.array(l)\n",
    "    \n",
    "    def l2(self , x):\n",
    "        #l2ノルムで正規化する（単位ベクトル化）\n",
    "        l2 = x / np.sqrt(np.sum(x**2))\n",
    "        \n",
    "        return l2\n",
    "    \n",
    "    def tf_idf(self):\n",
    "        x = self.tf() * self.idf()\n",
    "        #各行にl2ノルムの正規化を適用\n",
    "        return np.array([self.l2(a) for a in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TF_IDF2(mini_data)\n",
    "tf_idf = tf.tf_idf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.201328677102573\n",
      "2.201328677102573\n",
      "1.994387551089178\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(tf_idf[0]))\n",
    "print(np.sum(tf_idf[1]))\n",
    "print(np.sum(tf_idf[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1956355375164818\n",
      "2.201328677102573\n",
      "1.977388147087266\n"
     ]
    }
   ],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "bow_train = (vectorizer.fit_transform(mini_data)).toarray()\n",
    "df = pd.DataFrame(bow_train , columns=vectorizer.get_feature_names())\n",
    "print(np.sum(bow_train[0]))\n",
    "print(np.sum(bow_train[1]))\n",
    "print(np.sum(bow_train[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークを用いてベクトル化を行う手法が Word2Vec です。\n",
    "\n",
    "\n",
    "BoWやTF-IDFはone-hot表現であったため、得られるベクトルの次元は語彙数分になります。そのため、語彙数を増やしにくいという問題があります。一方で、Word2Vecでは単語を任意の次元のベクトルに変換します。これをを Word Embedding（単語埋め込み） や 分散表現 と呼びます。変換操作を「ベクトル空間に埋め込む」と言うことが多いです。\n",
    "\n",
    "\n",
    "Word2VecにはCBoWとSkip-gramという2種類の仕組みがあるため順番に見ていきます。\n",
    "\n",
    "\n",
    "CBoW\n",
    "CBoW (Continuous Bag-of-Words) によるWord2Vecではある単語とある単語の間に来る単語を推定できるように全結合層2層のニューラルネットワークを学習します。\n",
    "\n",
    "\n",
    "単語はコーパスの語彙数次元のone-hot表現を行なっておきます。そのため、入力と出力の次元は語彙数と同じになります。一方で、中間のノード数をWord2Vecにより得たい任意の次元数とします。これにより全結合層の重みは「得たい次元のノード数×語彙数」になります。このネットワークにより学習を行なった後、出力側の重みを取り出すことで、各語彙を表すベクトルを手に入れることができます。\n",
    "\n",
    "\n",
    "間の単語の推定を行なっているため、同じ箇所で代替可能な言葉は似たベクトルになるというメリットもあります。これはBoWやTF-IDFでは得られない情報です。\n",
    "\n",
    "\n",
    "あるテキストは「そのテキストの長さ（単語数）×Word2Vecで得た分散表現の次元数」の配列になりますが、各入力の配列を揃える必要があるモデルに入力するためには、短いテキストは空白を表す単語を加える パディング を行なったり、長いテキストは単語を消したりします。テキストを 固定長 にすると呼びます。\n",
    "\n",
    "\n",
    "ウィンドウサイズ\n",
    "入力する単語は推定する前後1つずつだけでなく、複数個とする場合もあります。前後いくつを見るかの大きさを ウィンドウサイズ と呼びます。\n",
    "\n",
    "\n",
    "Skip-gram\n",
    "CBoWとは逆にある単語の前後の単語を推定できるように全結合層2層のニューラルネットワークを学習する方法が Skip-gram です。学習を行なった後は入力側の重みを取り出し各語彙を表すベクトルとします。現在一般的に使われているのはCBoWよりもSki-gramです。\n",
    "\n",
    "\n",
    "利用方法\n",
    "Pythonでは Gensim ライブラリを用いて扱うことができます。\n",
    "\n",
    "\n",
    "gensim: models.word2vec – Word2vec embeddings\n",
    "\n",
    "\n",
    "BoWの例と同じ文章で学習してみます。CountVectorizerと異なり前処理を自動的に行なってはくれないため、単語（トークン）はリストで分割しておきます。また、大文字は小文字に揃え、記号は取り除きます。\n",
    "\n",
    "\n",
    "デフォルトのパラメータではCBoWで計算されます。また、ウィンドウサイズはwindow=5に設定されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.2-cp36-cp36m-macosx_10_9_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 30.4 MB/s eta 0:00:01   |████████▉                       | 6.5 MB 1.1 MB/s eta 0:00:16     |█████████████████▍              | 12.9 MB 1.3 MB/s eta 0:00:09     |██████████████████████▌         | 16.6 MB 769 kB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/apple/.local/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /Users/apple/.local/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/apple/.local/lib/python3.6/site-packages (from gensim) (1.18.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-1.11.1.tar.gz (105 kB)\n",
      "\u001b[K     |████████████████████████████████| 105 kB 505 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /Users/apple/.local/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: boto in /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.48.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.12.42-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 409 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/apple/.local/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /Users/apple/.local/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /Users/apple/.local/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/apple/.local/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 557 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.16.0,>=1.15.42\n",
      "  Downloading botocore-1.15.42-py2.py3-none-any.whl (6.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.1 MB 817 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.42->boto3->smart-open>=1.8.1->gensim) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.42->boto3->smart-open>=1.8.1->gensim) (2.6.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.11.1-py3-none-any.whl size=95255 sha256=668f1dde2091c36b6edd6057f8d201cac0b8acb83d8fa6b8bff4f398abb5e568\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/89/6b/f0/391fb74c038a4b87d4ac6ef4cd4c96ea820ec39b60f78d03a1\n",
      "Successfully built smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.12.42 botocore-1.15.42 gensim-3.8.2 jmespath-0.9.5 s3transfer-0.3.3 smart-open-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "語彙の一覧 : dict_keys(['this', 'movie', 'is', 'very', 'good', 'film', 'a', 'bad'])\n",
      "thisのベクトル : \n",
      "[ 0.03884272 -0.03484932 -0.03924293 -0.00516608  0.01237799  0.01782521\n",
      "  0.03781011 -0.01596084  0.01485014  0.02464964]\n",
      "movieのベクトル : \n",
      "[-0.04081175  0.01767913 -0.04324322  0.03334064 -0.00117866 -0.04398617\n",
      " -0.02996933  0.04711305 -0.00497666  0.00169678]\n",
      "isのベクトル : \n",
      "[ 0.02455612  0.03430059  0.02413583 -0.03429679 -0.04066877 -0.0204979\n",
      " -0.04698607  0.04883166 -0.03391479 -0.02782011]\n",
      "veryのベクトル : \n",
      "[-0.04612647 -0.02168088  0.04908155  0.02963647  0.03245099 -0.04209697\n",
      " -0.02872722  0.0300161  -0.0227239  -0.01966136]\n",
      "goodのベクトル : \n",
      "[ 0.01863581 -0.04840856 -0.00535998  0.00723026 -0.01236279 -0.03315582\n",
      "  0.03674081  0.00950481 -0.00368871  0.01753785]\n",
      "filmのベクトル : \n",
      "[ 0.00117126  0.03006574 -0.04418568  0.04894169 -0.01926022  0.00830618\n",
      " -0.03598302  0.01012192 -0.04316878 -0.00191328]\n",
      "aのベクトル : \n",
      "[ 0.02629136  0.01677017  0.04813191 -0.02960331 -0.04839702 -0.02744369\n",
      "  0.01683551  0.04388301 -0.0307835   0.03603281]\n",
      "badのベクトル : \n",
      "[-0.00582793  0.02280078  0.0229718   0.04975072  0.00922029 -0.01609987\n",
      " -0.0078186   0.04545268 -0.02995596  0.00225538]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/gensim/models/base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "/Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "sentences = [['this', 'movie', 'is', 'very', 'good'], ['this', 'film', 'is', 'a', 'good'], ['very', 'bad', 'very', 'very', 'bad']]\n",
    "model = Word2Vec(min_count = 1 , size = 10)#次元数を10に設定\n",
    "model.build_vocab(sentences)#準備\n",
    "model.train(sentences , total_examples = model.corpus_count , epochs = model.iter)#学習\n",
    "\n",
    "print(\"語彙の一覧 : {}\".format(model.wv.vocab.keys()))\n",
    "\n",
    "for vocab in model.wv.vocab.keys():\n",
    "    print(\"{}のベクトル : \\n{}\".format(vocab , model.wv[vocab]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語の距離\n",
    "ベクトル間で計算を行うことで、ある単語に似たベクトルを持つ単語を見つけることができます。 例えばgoodに似たベクトルの単語を３つ探します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 0.5325943231582642),\n",
       " ('a', 0.30311304330825806),\n",
       " ('very', 0.012908760458230972)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=\"good\" , topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可視化¶\n",
    "2次元に圧縮することで単語ごとの位置関係を可視化することができます。以下はt-SNEを用いた例です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cefbbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "vocabs = model.wv.vocab.keys()\n",
    "\n",
    "tsne_model = TSNE(perplexity=40 , n_components=2 , init=\"pca\" , n_iter=500 , random_state=23)\n",
    "vectors_tsne = tsne_model.fit_transform(model[vocabs])\n",
    "\n",
    "fig , ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(vectors_tsne[: , 0] , vectors_tsne[: , 1])\n",
    "for i , word in enumerate(list(vocabs)):\n",
    "    plt.annotate(word , xy=(vectors_tsne[i , 0] , vectors_tsne[i , 1]))\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題5】コーパスの前処理¶\n",
    "コーパスの前処理として、特殊文字（!など）やURLの除去、大文字の小文字化といったことを行なってください。また、単語（トークン）はリストで分割してください。\n",
    "https://datumstudio.jp/blog/python%E3%81%AB%E3%82%88%E3%82%8B%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%89%8D%E5%87%A6%E7%90%86%E5%82%99%E5%BF%98%E9%8C%B2\n",
    "\n",
    "https://qiita.com/kenTee/items/dcf63aa2895122bb3fd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"This movie is SOOOO funny!!!\",\n",
    "                        \"What a movie! I never\" , \n",
    "                        \"best movie ever!!!!! this movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "train_review = load_files('./aclImdb/train/', encoding='utf-8')\n",
    "x_train , y_train = train_review.data , train_review.target\n",
    "\n",
    "test_review = load_files('./aclImdb/test/', encoding='utf-8')\n",
    "x_test , y_test = test_review.data , test_review.target\n",
    "\n",
    "#ラベルの0,1と意味の対応の表示\n",
    "print(train_review.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus(x):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i].lower()#大文字を小文字へ\n",
    "        x[i] = x[i].replace(\"!\" , \"\").strip()#[!]を削除\n",
    "        x[i] = x[i].replace(\"?\" , \"\").strip()#[?]を削除\n",
    "        x[i] = x[i].replace(\"<br />\" , \"\").strip()\n",
    "        x[i] = re.sub(r\"https?://[\\w/:%#\\$&\\?\\(\\)~\\.=\\+\\-]+\", \"\", x[i])\n",
    "        x[i] = x[i].split()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = corpus(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'movie', 'is', 'soooo', 'funny'],\n",
       " ['what', 'a', 'movie', 'i', 'never'],\n",
       " ['best', 'movie', 'ever', 'this', 'movie']]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = corpus(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['zero',\n",
       "  'day',\n",
       "  'leads',\n",
       "  'you',\n",
       "  'to',\n",
       "  'think,',\n",
       "  'even',\n",
       "  're-think',\n",
       "  'why',\n",
       "  'two',\n",
       "  'boys/young',\n",
       "  'men',\n",
       "  'would',\n",
       "  'do',\n",
       "  'what',\n",
       "  'they',\n",
       "  'did',\n",
       "  '-',\n",
       "  'commit',\n",
       "  'mutual',\n",
       "  'suicide',\n",
       "  'via',\n",
       "  'slaughtering',\n",
       "  'their',\n",
       "  'classmates.',\n",
       "  'it',\n",
       "  'captures',\n",
       "  'what',\n",
       "  'must',\n",
       "  'be',\n",
       "  'beyond',\n",
       "  'a',\n",
       "  'bizarre',\n",
       "  'mode',\n",
       "  'of',\n",
       "  'being',\n",
       "  'for',\n",
       "  'two',\n",
       "  'humans',\n",
       "  'who',\n",
       "  'have',\n",
       "  'decided',\n",
       "  'to',\n",
       "  'withdraw',\n",
       "  'from',\n",
       "  'common',\n",
       "  'civility',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'define',\n",
       "  'their',\n",
       "  'own/mutual',\n",
       "  'world',\n",
       "  'via',\n",
       "  'coupled',\n",
       "  'destruction.it',\n",
       "  'is',\n",
       "  'not',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  'movie',\n",
       "  'but',\n",
       "  'given',\n",
       "  'what',\n",
       "  'money/time',\n",
       "  'the',\n",
       "  'filmmaker',\n",
       "  'and',\n",
       "  'actors',\n",
       "  'had',\n",
       "  '-',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'remarkable',\n",
       "  'product.',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'explaining',\n",
       "  'the',\n",
       "  'motives',\n",
       "  'and',\n",
       "  'actions',\n",
       "  'of',\n",
       "  'the',\n",
       "  'two',\n",
       "  'young',\n",
       "  'suicide/murderers',\n",
       "  'it',\n",
       "  'is',\n",
       "  'better',\n",
       "  'than',\n",
       "  \"'elephant'\",\n",
       "  '-',\n",
       "  'in',\n",
       "  'terms',\n",
       "  'of',\n",
       "  'being',\n",
       "  'a',\n",
       "  'film',\n",
       "  'that',\n",
       "  'gets',\n",
       "  'under',\n",
       "  'our',\n",
       "  \"'rationalistic'\",\n",
       "  'skin',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'far,',\n",
       "  'far',\n",
       "  'better',\n",
       "  'film',\n",
       "  'than',\n",
       "  'almost',\n",
       "  'anything',\n",
       "  'you',\n",
       "  'are',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'see.',\n",
       "  'flawed',\n",
       "  'but',\n",
       "  'honest',\n",
       "  'with',\n",
       "  'a',\n",
       "  'terrible',\n",
       "  'honesty.'],\n",
       " ['words',\n",
       "  \"can't\",\n",
       "  'describe',\n",
       "  'how',\n",
       "  'bad',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'is.',\n",
       "  'i',\n",
       "  \"can't\",\n",
       "  'explain',\n",
       "  'it',\n",
       "  'by',\n",
       "  'writing',\n",
       "  'only.',\n",
       "  'you',\n",
       "  'have',\n",
       "  'too',\n",
       "  'see',\n",
       "  'it',\n",
       "  'for',\n",
       "  'yourself',\n",
       "  'to',\n",
       "  'get',\n",
       "  'at',\n",
       "  'grip',\n",
       "  'of',\n",
       "  'how',\n",
       "  'horrible',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'really',\n",
       "  'can',\n",
       "  'be.',\n",
       "  'not',\n",
       "  'that',\n",
       "  'i',\n",
       "  'recommend',\n",
       "  'you',\n",
       "  'to',\n",
       "  'do',\n",
       "  'that.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'so',\n",
       "  'many',\n",
       "  'clichés,',\n",
       "  'mistakes',\n",
       "  '(and',\n",
       "  'all',\n",
       "  'other',\n",
       "  'negative',\n",
       "  'things',\n",
       "  'you',\n",
       "  'can',\n",
       "  'imagine)',\n",
       "  'here',\n",
       "  'that',\n",
       "  'will',\n",
       "  'just',\n",
       "  'make',\n",
       "  'you',\n",
       "  'cry.',\n",
       "  'to',\n",
       "  'start',\n",
       "  'with',\n",
       "  'the',\n",
       "  'technical',\n",
       "  'first,',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'mistakes',\n",
       "  'regarding',\n",
       "  'the',\n",
       "  'airplane.',\n",
       "  'i',\n",
       "  \"won't\",\n",
       "  'list',\n",
       "  'them',\n",
       "  'here,',\n",
       "  'but',\n",
       "  'just',\n",
       "  'mention',\n",
       "  'the',\n",
       "  'coloring',\n",
       "  'of',\n",
       "  'the',\n",
       "  'plane.',\n",
       "  'they',\n",
       "  \"didn't\",\n",
       "  'even',\n",
       "  'manage',\n",
       "  'to',\n",
       "  'show',\n",
       "  'an',\n",
       "  'airliner',\n",
       "  'in',\n",
       "  'the',\n",
       "  'colors',\n",
       "  'of',\n",
       "  'a',\n",
       "  'fictional',\n",
       "  'airline,',\n",
       "  'but',\n",
       "  'instead',\n",
       "  'used',\n",
       "  'a',\n",
       "  '747',\n",
       "  'painted',\n",
       "  'in',\n",
       "  'the',\n",
       "  'original',\n",
       "  'boeing',\n",
       "  'livery.',\n",
       "  'very',\n",
       "  'bad.',\n",
       "  'the',\n",
       "  'plot',\n",
       "  'is',\n",
       "  'stupid',\n",
       "  'and',\n",
       "  'has',\n",
       "  'been',\n",
       "  'done',\n",
       "  'many',\n",
       "  'times',\n",
       "  'before,',\n",
       "  'only',\n",
       "  'much,',\n",
       "  'much',\n",
       "  'better.',\n",
       "  'there',\n",
       "  'are',\n",
       "  'so',\n",
       "  'many',\n",
       "  'ridiculous',\n",
       "  'moments',\n",
       "  'here',\n",
       "  'that',\n",
       "  'i',\n",
       "  'lost',\n",
       "  'count',\n",
       "  'of',\n",
       "  'it',\n",
       "  'really',\n",
       "  'early.',\n",
       "  'also,',\n",
       "  'i',\n",
       "  'was',\n",
       "  'on',\n",
       "  'the',\n",
       "  'bad',\n",
       "  \"guys'\",\n",
       "  'side',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time',\n",
       "  'in',\n",
       "  'the',\n",
       "  'movie,',\n",
       "  'because',\n",
       "  'the',\n",
       "  'good',\n",
       "  'guys',\n",
       "  'were',\n",
       "  'so',\n",
       "  'stupid.',\n",
       "  '\"executive',\n",
       "  'decision\"',\n",
       "  'should',\n",
       "  'without',\n",
       "  'a',\n",
       "  'doubt',\n",
       "  'be',\n",
       "  \"you're\",\n",
       "  'choice',\n",
       "  'over',\n",
       "  'this',\n",
       "  'one,',\n",
       "  'even',\n",
       "  'the',\n",
       "  '\"turbulence\"-movies',\n",
       "  'are',\n",
       "  'better.',\n",
       "  'in',\n",
       "  'fact,',\n",
       "  'every',\n",
       "  'other',\n",
       "  'movie',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'is',\n",
       "  'better',\n",
       "  'than',\n",
       "  'this',\n",
       "  'one.'],\n",
       " ['everyone',\n",
       "  'plays',\n",
       "  'their',\n",
       "  'part',\n",
       "  'pretty',\n",
       "  'well',\n",
       "  'in',\n",
       "  'this',\n",
       "  '\"little',\n",
       "  'nice',\n",
       "  'movie\".',\n",
       "  'belushi',\n",
       "  'gets',\n",
       "  'the',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'live',\n",
       "  'part',\n",
       "  'of',\n",
       "  'his',\n",
       "  'life',\n",
       "  'differently,',\n",
       "  'but',\n",
       "  'ends',\n",
       "  'up',\n",
       "  'realizing',\n",
       "  'that',\n",
       "  'what',\n",
       "  'he',\n",
       "  'had',\n",
       "  'was',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'just',\n",
       "  'as',\n",
       "  'good',\n",
       "  'or',\n",
       "  'maybe',\n",
       "  'even',\n",
       "  'better.',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'shows',\n",
       "  'us',\n",
       "  'that',\n",
       "  'we',\n",
       "  'ought',\n",
       "  'to',\n",
       "  'take',\n",
       "  'advantage',\n",
       "  'of',\n",
       "  'the',\n",
       "  'opportunities',\n",
       "  'we',\n",
       "  'have,',\n",
       "  'not',\n",
       "  'the',\n",
       "  'ones',\n",
       "  'we',\n",
       "  'do',\n",
       "  'not',\n",
       "  'or',\n",
       "  'cannot',\n",
       "  'have.',\n",
       "  'if',\n",
       "  'u',\n",
       "  'can',\n",
       "  'get',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'on',\n",
       "  'video',\n",
       "  'for',\n",
       "  'around',\n",
       "  '$10,',\n",
       "  'it´d',\n",
       "  'be',\n",
       "  'an',\n",
       "  'investment'],\n",
       " ['there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'highly',\n",
       "  'talented',\n",
       "  'filmmakers/actors',\n",
       "  'in',\n",
       "  'germany',\n",
       "  'now.',\n",
       "  'none',\n",
       "  'of',\n",
       "  'them',\n",
       "  'are',\n",
       "  'associated',\n",
       "  'with',\n",
       "  'this',\n",
       "  '\"movie\".why',\n",
       "  'in',\n",
       "  'the',\n",
       "  'world',\n",
       "  'do',\n",
       "  'producers',\n",
       "  'actually',\n",
       "  'invest',\n",
       "  'money',\n",
       "  'in',\n",
       "  'something',\n",
       "  'like',\n",
       "  'this',\n",
       "  'this',\n",
       "  'you',\n",
       "  'could',\n",
       "  'have',\n",
       "  'made',\n",
       "  '10',\n",
       "  'good',\n",
       "  'films',\n",
       "  'with',\n",
       "  'the',\n",
       "  'budget',\n",
       "  'of',\n",
       "  'this',\n",
       "  'garbage',\n",
       "  \"it's\",\n",
       "  'not',\n",
       "  'entertaining',\n",
       "  'to',\n",
       "  'have',\n",
       "  'seven',\n",
       "  'grown',\n",
       "  'men',\n",
       "  'running',\n",
       "  'around',\n",
       "  'as',\n",
       "  'dwarfs,',\n",
       "  'pretending',\n",
       "  'to',\n",
       "  'be',\n",
       "  'funny.',\n",
       "  'what',\n",
       "  'is',\n",
       "  'funny',\n",
       "  'though',\n",
       "  'is',\n",
       "  'that',\n",
       "  'the',\n",
       "  \"film's\",\n",
       "  'producer',\n",
       "  '(who',\n",
       "  'happens',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'oldest',\n",
       "  'guy',\n",
       "  'of',\n",
       "  'the',\n",
       "  'bunch)',\n",
       "  'is',\n",
       "  'playing',\n",
       "  'the',\n",
       "  'youngest',\n",
       "  'dwarf.the',\n",
       "  'film',\n",
       "  'is',\n",
       "  'filled',\n",
       "  'with',\n",
       "  'moments',\n",
       "  'that',\n",
       "  'scream',\n",
       "  'for',\n",
       "  'captions',\n",
       "  'saying',\n",
       "  '\"you\\'re',\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'laugh',\n",
       "  'now\".',\n",
       "  \"it's\",\n",
       "  'hard',\n",
       "  'to',\n",
       "  'believe',\n",
       "  'that',\n",
       "  'this',\n",
       "  \"crap's\",\n",
       "  'supposed',\n",
       "  'to',\n",
       "  'be',\n",
       "  'a',\n",
       "  'comedy.many',\n",
       "  'people',\n",
       "  'actually',\n",
       "  'stood',\n",
       "  'up',\n",
       "  'and',\n",
       "  'left',\n",
       "  'the',\n",
       "  'cinema',\n",
       "  '30',\n",
       "  'minutes',\n",
       "  'into',\n",
       "  'the',\n",
       "  'movie.',\n",
       "  'i',\n",
       "  'should',\n",
       "  'have',\n",
       "  'done',\n",
       "  'the',\n",
       "  'same',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'wasting',\n",
       "  'my',\n",
       "  'time...pain'],\n",
       " [\"i've\",\n",
       "  'just',\n",
       "  'had',\n",
       "  'the',\n",
       "  'evidence',\n",
       "  'that',\n",
       "  'confirmed',\n",
       "  'my',\n",
       "  'suspicions.',\n",
       "  'a',\n",
       "  'bunch',\n",
       "  'of',\n",
       "  'kids,',\n",
       "  '14',\n",
       "  'to',\n",
       "  '22',\n",
       "  'put',\n",
       "  'on',\n",
       "  'the',\n",
       "  'dvd',\n",
       "  'of',\n",
       "  '\"titanic\"',\n",
       "  'on',\n",
       "  'a',\n",
       "  'fantastic',\n",
       "  'state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'art',\n",
       "  'mega',\n",
       "  'screen',\n",
       "  'home',\n",
       "  'entertainment',\n",
       "  'type',\n",
       "  'deal.',\n",
       "  'only',\n",
       "  'two',\n",
       "  'of',\n",
       "  'them',\n",
       "  'had',\n",
       "  'actually',\n",
       "  'seen',\n",
       "  'it',\n",
       "  'before.',\n",
       "  'but',\n",
       "  'they',\n",
       "  'all',\n",
       "  'had',\n",
       "  'seen',\n",
       "  'the',\n",
       "  'moment',\n",
       "  'of',\n",
       "  'kate,',\n",
       "  'leo',\n",
       "  'and',\n",
       "  'celine',\n",
       "  'dion',\n",
       "  'so',\n",
       "  'many',\n",
       "  'times',\n",
       "  'that',\n",
       "  'most',\n",
       "  'of',\n",
       "  'them',\n",
       "  'felt',\n",
       "  'they',\n",
       "  'had',\n",
       "  'seen',\n",
       "  'the',\n",
       "  'whole',\n",
       "  'movie.',\n",
       "  'shortly',\n",
       "  'after',\n",
       "  'the',\n",
       "  'epic',\n",
       "  'started,',\n",
       "  'they',\n",
       "  'started',\n",
       "  'to',\n",
       "  'get',\n",
       "  'restless,',\n",
       "  'some',\n",
       "  'of',\n",
       "  'them',\n",
       "  'left',\n",
       "  'asking',\n",
       "  'the',\n",
       "  'others',\n",
       "  '--',\n",
       "  '\"call',\n",
       "  'us',\n",
       "  'when',\n",
       "  'the',\n",
       "  'iceberg',\n",
       "  'appears\"',\n",
       "  'over',\n",
       "  'an',\n",
       "  'hour',\n",
       "  'and',\n",
       "  'a',\n",
       "  'half',\n",
       "  'into',\n",
       "  'the',\n",
       "  'movie,',\n",
       "  'only',\n",
       "  'the',\n",
       "  'two',\n",
       "  'girls',\n",
       "  'who',\n",
       "  'had',\n",
       "  'seen',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'before,',\n",
       "  'were',\n",
       "  'still',\n",
       "  'there.',\n",
       "  'they',\n",
       "  'started',\n",
       "  'shouting:',\n",
       "  'iceberg,',\n",
       "  'iceberg.',\n",
       "  'a',\n",
       "  'stampede',\n",
       "  'followed,',\n",
       "  'they',\n",
       "  'all',\n",
       "  'came',\n",
       "  'back',\n",
       "  'to',\n",
       "  'see',\n",
       "  'the',\n",
       "  'sinking',\n",
       "  'of',\n",
       "  'the',\n",
       "  'titanic.',\n",
       "  'they',\n",
       "  'sat',\n",
       "  'open',\n",
       "  'mouthed,',\n",
       "  'emitting',\n",
       "  'ohs',\n",
       "  'and',\n",
       "  'far',\n",
       "  'outs.',\n",
       "  'so,',\n",
       "  'just',\n",
       "  'like',\n",
       "  'i',\n",
       "  'thought',\n",
       "  'when',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'first',\n",
       "  'burst',\n",
       "  'into',\n",
       "  'the',\n",
       "  'scene.',\n",
       "  'what',\n",
       "  'is',\n",
       "  'this',\n",
       "  'one',\n",
       "  'and',\n",
       "  'a',\n",
       "  'half',\n",
       "  'hours',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'the',\n",
       "  'bloody',\n",
       "  'thing',\n",
       "  'to',\n",
       "  'sink',\n",
       "  'but',\n",
       "  'what',\n",
       "  'about',\n",
       "  'the',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'the',\n",
       "  'of',\n",
       "  'it.',\n",
       "  'dr.',\n",
       "  'zivagho,',\n",
       "  'for',\n",
       "  'instance,',\n",
       "  'had',\n",
       "  'a',\n",
       "  'similar',\n",
       "  'running',\n",
       "  'time,',\n",
       "  'but',\n",
       "  'think',\n",
       "  'how',\n",
       "  'much',\n",
       "  'takes',\n",
       "  'place',\n",
       "  'in',\n",
       "  'that',\n",
       "  'film',\n",
       "  'within',\n",
       "  'the',\n",
       "  'same',\n",
       "  'period',\n",
       "  'of',\n",
       "  'time.',\n",
       "  'in',\n",
       "  '\"titanic\"',\n",
       "  'leo',\n",
       "  'teaches',\n",
       "  'kate',\n",
       "  'how',\n",
       "  'to',\n",
       "  'spit.',\n",
       "  'look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'faces',\n",
       "  'and',\n",
       "  'hands',\n",
       "  'of',\n",
       "  'the,',\n",
       "  'supposedly,',\n",
       "  'creme',\n",
       "  'de',\n",
       "  'la',\n",
       "  'creme',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'class',\n",
       "  'dining',\n",
       "  'room',\n",
       "  'of',\n",
       "  'the',\n",
       "  'ship.',\n",
       "  'look',\n",
       "  'at',\n",
       "  'the',\n",
       "  'historical',\n",
       "  'details,',\n",
       "  'if',\n",
       "  'you',\n",
       "  'can',\n",
       "  'find',\n",
       "  'them.',\n",
       "  'the',\n",
       "  'storyline',\n",
       "  'is',\n",
       "  'so',\n",
       "  'thin',\n",
       "  'that',\n",
       "  'they',\n",
       "  'have',\n",
       "  'to',\n",
       "  'introduce',\n",
       "  'guns',\n",
       "  'and',\n",
       "  'shootings',\n",
       "  'in',\n",
       "  'a',\n",
       "  'ship',\n",
       "  'that',\n",
       "  'is',\n",
       "  'about',\n",
       "  'to',\n",
       "  'sink.',\n",
       "  'the',\n",
       "  'real',\n",
       "  'sinking',\n",
       "  'here',\n",
       "  'is',\n",
       "  'of',\n",
       "  'film',\n",
       "  'standards.',\n",
       "  'all',\n",
       "  'the',\n",
       "  'efforts',\n",
       "  'are',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'special',\n",
       "  'effects',\n",
       "  'and',\n",
       "  'opening',\n",
       "  'week',\n",
       "  'ends.',\n",
       "  'the',\n",
       "  'film',\n",
       "  'went',\n",
       "  'on',\n",
       "  'to',\n",
       "  'become',\n",
       "  'the',\n",
       "  'highest',\n",
       "  'grossing',\n",
       "  'movie',\n",
       "  'of',\n",
       "  'all',\n",
       "  'time',\n",
       "  'so,',\n",
       "  'what',\n",
       "  'do',\n",
       "  'i',\n",
       "  'know']]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題6】Word2Vecの学習\n",
    "Word2Vecの学習を行なってください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/gensim/models/base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n",
      "/Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = xt\n",
    "model =Word2Vec(min_count = 1, size = 10)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences, total_examples= model.corpus_count, epochs= model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
