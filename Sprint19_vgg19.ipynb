{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:08:26.011539Z",
     "start_time": "2019-09-25T07:08:20.644512Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "#VGG\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/apple/diveintocode-ml/Sprint19'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "#csvを読み込む方法？カレントディレクトリの変更？\n",
    "train = pd.read_csv('train .csv')\n",
    "test = pd.read_csv('sample_submission.csv')\n",
    "depth = pd.read_csv('depths.csv')\n",
    "\n",
    "train_src = './train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/\n"
     ]
    }
   ],
   "source": [
    "print(train_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "#元のNumpy配列と同期され続けるコピーを作る場合は、np.asarray\n",
    "X_train = np.asarray(\n",
    "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "#4000枚、縦横101ピクセルの画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x137083be0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x138d19278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#0~4000の間でランダムな値\n",
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3914"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "949"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder features - ResNet50:\n",
    "エンコードは画像の特徴量を圧縮\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T07:09:31.695684Z",
     "start_time": "2019-09-25T07:09:24.147636Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 13s 0us/step\n",
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "#base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model = VGG19(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "#unet_vgg16\n",
    "def unet_vgg19(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    #\n",
    "    base_model = VGG19(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    # Layers for feature extraction in the encoder part\n",
    "    #activation→block\n",
    "    encoder1 = base_model.get_layer('block1_pool').output\n",
    "    encoder2 = base_model.get_layer('block2_pool').output\n",
    "    encoder3 = base_model.get_layer('block3_pool').output\n",
    "    encoder4 = base_model.get_layer('block4_pool').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-38-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /Users/apple/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 27,920,897\n",
      "Trainable params: 27,918,785\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg19(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv4 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv4 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv4 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 384)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   221248      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 192)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   110656      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 33,987,185\n",
      "Trainable params: 33,981,905\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 2 samples\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 45s 4s/step - loss: 1.1860 - my_iou_metric: 0.3100 - val_loss: 4.0379 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_vgg19.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "model_depth = unet_vgg19(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg19.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 1  # 25\n",
    "batch_size = 16\n",
    "\n",
    "X_tr=X_tr[:10]\n",
    "y_tr=y_tr[:10]\n",
    "X_val=X_val[:2]\n",
    "y_val=y_val[:2] \n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]\u001b[A\n",
      " 34%|███▍      | 12/35 [00:00<00:00, 116.35it/s]\u001b[A\n",
      "100%|██████████| 35/35 [00:00<00:00, 115.67it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.5500 at threshold: 0.380\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.408571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.243892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.408571\n",
       "std     0.204939   0.243892\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.275000\n",
       "50%     0.540000   0.550000\n",
       "75%     0.710000   0.550000\n",
       "max     0.880000   0.550000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x196868eb8>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19e3d82e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-25T08:26:39.786782Z",
     "start_time": "2019-09-25T08:26:39.781446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(0.7 > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou_vector(A, B):\n",
    "    # Numpy version\n",
    "    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
