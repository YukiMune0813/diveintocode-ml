{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.MNISTデータセット\n",
    "\n",
    "ニューラルネットワークスクラッチの検証にはMNISTデータセットを使用します。各種ライブラリやサイトからダウンロードできますが、ここでは深層学習フレームワークのKerasを用います。以下のコードを実行すればデータセットをダウンロードし、展開まで行えます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《MNISTとは？》\n",
    "\n",
    "\n",
    "画像分類のための定番データセットで、手書き数字認識を行います。このデータセットには訓練用6万枚、テスト用1万枚の28×28ピクセルの白黒画像、およびそれらが0〜9のどの数字であるかというラベルが含まれています。\n",
    "\n",
    "\n",
    "《画像データとは？》\n",
    "\n",
    "\n",
    "デジタル画像は点の集合で、これをピクセルと呼びます。一般的に白黒画像であればピクセルには0〜255の値が含まれます。一方、カラー画像であればR（赤）、G（緑）、B（青）それぞれに対応する0〜255の値が含まれます。機械学習をする上では、この0〜255の値一つひとつが特徴量として扱われます。0〜255は符号なしの8ビット整数で表せる範囲になるため、NumPyであれば「uint8」型の変数として保持できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの確認\n",
    "どういったデータなのかを見てみます。\n",
    "各データは28×28ピクセルの白黒画像です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平滑化\n",
    "(1, 28, 28)の各画像を、(1, 784)に変換します。これまで学んできた機械学習手法や、今回扱う全結合層のみのニューラルネットワークではこの形で扱います。全てのピクセルが一列になっていることを、 平滑化（flatten） してあるという風に表現します。\n",
    "ここまで機械学習を学んでくる中で、特徴量の数を「次元」と呼んできました。その視点ではMNISTは784次元のデータです。一方で、NumPyのshapeが(784,)の状態を1次元配列とも呼びます。画像としての縦横の情報を持つ（28, 28)の状態であれば、2次元配列です。この視点では2次元のデータです。さらに、もしもカラー画像であれば(28, 28, 3)ということになり、3次元配列です。先ほどの視点では3次元のデータになります。しかし、白黒でもカラーでも平面画像であり、立体データではないという視点で、2次元のデータです。画像データを扱う際にはこのように「次元」という言葉が複数の意味合いで使われることに注意してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1 , 784)\n",
    "X_test = X_test.reshape(-1 , 784)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像データの可視化\n",
    "画像データを可視化します。plt.imshowに渡します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d90fe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28 , 28)\n",
    "#X_train[index] : (784,)\n",
    "#image : (28,28)\n",
    "plt.imshow(image , \"gray\")\n",
    "plt.title(\"label : {}\".format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "《発展的話題》\n",
    "\n",
    "\n",
    "画像データは符号なし8ビット整数のuint8型で保持されることが一般的ですが、plt.imshowはより自由な配列を画像として表示することが可能です。例えば、以下のようにマイナスの値を持ったfloat64型の浮動小数点であってもエラーにはならないし、先ほどと全く同じ風に表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12da67128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float)#float型に変換\n",
    "image -= 105.35 #意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image , \"gray\")\n",
    "plt.title(\"label : {}\".format(y_train[index]))\n",
    "plt.show()\n",
    "print(image)#値を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これは、自動的に値を0〜255の整数に変換して処理するように作られているからです。uint8型であっても最小値が0、最大値が255でない場合には色合いがおかしくなります。それを防ぐためには次のように引数を入れてください。\n",
    "画像関係のライブラリではこの自動的なスケーリングが思わぬ結果を生むことがあるので、新しいメソッドを使うときには確認しておきましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12daecf60>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d926828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理\n",
    "画像は0から255のuint8型で表されますが、機械学習をする上では0から1のfloat型で扱うことになります。以下のコードで変換可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max())#1.0\n",
    "print(X_train.min())#0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、正解ラベルは0から9の整数ですが、ニューラルネットワークで多クラス分類を行う際には one-hot表現 に変換します。scikit-learnのOneHotEncoderを使用したコードが以下です。このone-hot表現による値はそのラベルである確率を示していることになるため、float型で扱います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、訓練データ6万枚の内2割を検証データとして分割してください。訓練データが48000枚、検証データが12000枚となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_val , y_train , y_val = train_test_split(\n",
    "             X_train , y_train_one_hot , test_size = 0.20)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ニューラルネットワークスクラッチ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークのクラスをスクラッチで作成していきます。NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "\n",
    "今回は多クラス分類を行う3層のニューラルネットワークを作成します。層の数などは固定した上でニューラルネットワークの基本を学びます。次のSprintで層を自由に変えられる設計にしていきます。\n",
    "\n",
    "\n",
    "以下に雛形を用意してあります。このScratchSimpleNeuralNetrowkClassifierクラスにコードを書き加えていってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチ処理\n",
    "これまでの機械学習スクラッチでは、全てのサンプルを一度に計算していました。しかし、ニューラルネットワークではデータを分割して入力する 確率的勾配降下法 が一般的です。分割した際のひとかたまりを ミニバッチ 、そのサンプル数を バッチサイズ と呼びます。\n",
    "\n",
    "今回はバッチサイズを20とします。今回使う訓練用データは48000枚ですから、48000÷20で2400回の更新を繰り返すことになります。ニューラルネットワークではこれを2400回 イテレーション（iteration） すると呼びます。訓練用データを一度全て見ると1回の エポック（epoch） が終わったことになります。このエポックを複数回繰り返し、学習が完了します。\n",
    "\n",
    "これを実現するための簡素なイテレータを用意しました。for文で呼び出すと、ミニバッチを取得できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "ニューラルネットワークの学習はフォワードプロパゲーションとバックプロパゲションの繰り返しになります。\n",
    "\n",
    "\n",
    "### 【問題1】重みの初期値を決めるコードの作成\n",
    "\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# W1: (784, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20 # バッチサイズ\n",
    "n_features = X_train.shape[1] # 特徴量の数\n",
    "n_nodes1 = 400 # 1層目のノード数\n",
    "n_nodes2 = 200 # 2層目のノード数\n",
    "n_output = 10 # 出力のクラス数（3層目のノード数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 400)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_value(n_features , n_nodes1,n_nodes2, n_output , sigma):\n",
    "    W1 = sigma * np.random.rand(n_features , n_nodes1)#一層目の重み\n",
    "    W2 = sigma * np.random.rand(n_nodes1 , n_nodes2)#二層目の重み\n",
    "    W_out = sigma * np.random.rand(n_nodes2 , n_output)#出力層の重み\n",
    "    b1 = np.zeros(n_nodes1)#一層目のバイアス\n",
    "    b2 = np.zeros(n_nodes2)#二層目のバイアス\n",
    "    b_out = np.zeros(n_output)#出力層のバイアス\n",
    "    return W1,W2,W_out,b1,b2,b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#それぞれの重みとバイアスを取得\n",
    "W1 , W2 , W_out , b1 , b2 , b_out = initial_value(n_features , n_nodes1,n_nodes2, n_output , sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = X_train.shape[1]\n",
    "mask =  np.random.choice(train_size , batch_size)\n",
    "X_batch = X_train[mask]\n",
    "A1 = np.dot(X_batch , W1) + b1\n",
    "A1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_1 = 1 / (1 + np.exp(-A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = np.tanh(A1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "# print(len(get_mini_batch)) # 2400\n",
    "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    A1 = np.dot(mini_X_train , W1) + b1\n",
    "    Z1 = np.tanh(A1)\n",
    "    A2 = np.dot(Z1 , W2) + b2\n",
    "    Z2 = np.tanh(A2)\n",
    "    A3 = np.dot(Z2 , W_out) + b_out\n",
    "    Z3 = Z = np.exp(A3) / np.sum(np.exp(A3))\n",
    "#     print(Z3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.exp(A1[-1]) / np.sum(np.exp(A1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(a):\n",
    "    return 1 / (1 + np.exp(-a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp = np.sum(exp_a)\n",
    "    z = exp_a / sum_exp\n",
    "    return z#「2層目の活性化関数」\n",
    "Z2 = np.tanh(A2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 \n",
    "L\n",
    " は次の数式です。\n",
    " $$\n",
    " L = - \\frac{1}{n_b}\\sum_{j}^{n_b}\\sum_{k}^{n_c}y_{jk} log(z_{3\\_jk})\n",
    "$$\n",
    "y\n",
    "i\n",
    "j\n",
    " : \n",
    "j\n",
    " 番目のサンプルの \n",
    "k\n",
    " 番目のクラスの正解ラベル（one-hot表現で0か1のスカラー）\n",
    "\n",
    "\n",
    "z\n",
    "3\n",
    "i\n",
    "j\n",
    " : \n",
    "j\n",
    " 番目のサンプルの \n",
    "k\n",
    " 番目のクラスの確率（スカラー）\n",
    "\n",
    "\n",
    "n\n",
    "b\n",
    " : バッチサイズ、batch_size\n",
    "\n",
    "\n",
    "n\n",
    "c\n",
    " : クラスの数、n_output（今回のMNISTでは10）\n",
    "\n",
    "\n",
    "サンプル1つあたりの誤差が求まります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "\n",
    "# print(len(get_mini_batch)) # 2400\n",
    "# print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    A1 = np.dot(mini_X_train , W1) + b1\n",
    "    Z1 = np.tanh(A1)\n",
    "    A2 = np.dot(Z1 , W2) + b2\n",
    "    Z2 = np.tanh(A2)\n",
    "    A3 = np.dot(Z2 , W_out) + b_out\n",
    "    Z3 = Z = np.exp(A3) / np.sum(np.exp(A3))\n",
    "    L = -np.sum(mini_y_train * np.log(Z3)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y , z):\n",
    "    if y.ndim == 1: #次元数が１ならば、\n",
    "        z = z.reshape(1 , z.size)\n",
    "        y = y.reshape(1 , y.size)\n",
    "\n",
    "    error = -np.sum(y[np.arange(batch_size)] * np.log(z) + 1e-7) / batch_size \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.303584499813843"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y_train_one_hot, Z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 \n",
    "W\n",
    "i\n",
    " と \n",
    "B\n",
    "i\n",
    " に対し、更新後の \n",
    "W\n",
    "′\n",
    "i\n",
    " と \n",
    "B\n",
    "′\n",
    "i\n",
    " は次の数式で求められます。\n",
    "\n",
    "$$\n",
    "W_i^{\\prime} = W_i - \\alpha \\frac{\\partial L}{\\partial W_i} \\\\<br/>B_i^{\\prime} = B_i - \\alpha \\frac{\\partial L}{\\partial B_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "α\n",
    " : 学習率（層ごとに変えることも可能だが、基本的には全て同じとする）\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "W\n",
    "i\n",
    " : \n",
    "W\n",
    "i\n",
    " に関する損失 \n",
    "L\n",
    " の勾配\n",
    "\n",
    "\n",
    "∂\n",
    "L\n",
    "∂\n",
    "B\n",
    "i\n",
    " : \n",
    "B\n",
    "i\n",
    " に関する損失 \n",
    "L\n",
    " の勾配\n",
    "\n",
    "\n",
    "＊この勾配はミニバッチのサンプル数分の合計または平均を考えます。ここでは合計を計算します。\n",
    "\n",
    "\n",
    "この更新方法はSprint3線形回帰やsprint4ロジスティック回帰における最急降下法と同様です。より効果的な更新方法が知られており、それは次のSprintで扱います。\n",
    "\n",
    "\n",
    "勾配 \n",
    "∂\n",
    "L\n",
    "∂\n",
    "W\n",
    "i\n",
    " や \n",
    "∂\n",
    "L\n",
    "∂\n",
    "B\n",
    "i\n",
    " を求めるために、バックプロパゲーションを行います。以下の数式です。ハイパボリックタンジェント関数を使用した例を載せました。シグモイド関数の場合の数式はその後ろにあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    y = (1 - sigmoid(x)) * sigmoid(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24094791, 0.24015754, 0.24079708, ..., 0.24031549, 0.24036075,\n",
       "        0.24217076],\n",
       "       [0.22724787, 0.22848289, 0.2307437 , ..., 0.22875329, 0.22924105,\n",
       "        0.23114128],\n",
       "       [0.24705421, 0.24658244, 0.24598613, ..., 0.24621749, 0.24723803,\n",
       "        0.24650248],\n",
       "       ...,\n",
       "       [0.24778682, 0.24738832, 0.24773734, ..., 0.24691016, 0.24796639,\n",
       "        0.24717019],\n",
       "       [0.20865019, 0.21127571, 0.20735096, ..., 0.20432098, 0.21431736,\n",
       "        0.20971367],\n",
       "       [0.21949371, 0.22254102, 0.21965678, ..., 0.21940144, 0.22057351,\n",
       "        0.22416662]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「3層目」\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_3} = Z_{3} - Y\\\\<br/>\\frac{\\partial L}{\\partial B_3} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{3\\_j}}\\\\<br/>\\frac{\\partial L}{\\partial W_3} = Z_{2}^{T}\\cdot \\frac{\\partial L}{\\partial A_3}\\\\<br/>\\frac{\\partial L}{\\partial Z_2} = \\frac{\\partial L}{\\partial A_3} \\cdot W_3^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「2層目」\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_2} = \\frac{\\partial L}{\\partial Z_2} \\odot \\{1-tanh^2(A_{2})\\}\\\\<br/>\\frac{\\partial L}{\\partial B_2} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{2\\_j}}\\\\<br/>\\frac{\\partial L}{\\partial W_2} = Z_{1}^T \\cdot \\frac{\\partial L}{\\partial A_2}\\\\<br/>\\frac{\\partial L}{\\partial Z_1} = \\frac{\\partial L}{\\partial A_2} \\cdot W_2^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「1層目」\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial A_1} = \\frac{\\partial L}{\\partial Z_1} \\odot \\{1-tanh^2(A_{1})\\}\\\\<br/>\\frac{\\partial L}{\\partial B_1} = \\sum_{j}^{n_b}\\frac{\\partial L}{\\partial A_{1\\_j}}\\\\<br/>\\frac{\\partial L}{\\partial W_1} = X^T \\cdot \\frac{\\partial L}{\\partial A_1}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self , epochs = 10 , alpha = 0.001 ,sigma = 0.01,n_nodes1= 400 , n_nodes2 = 200 , n_output = 10 , batch_size = 20, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        n_features = X_train.shape[1]\n",
    "        self.n_features = n_features\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "        self.loss = []\n",
    "        self.epochs = epochs\n",
    "     \n",
    "    #初期値\n",
    "    def init_network(self):\n",
    "        network = {}\n",
    "        network[\"W1\"] =  self.sigma * np.random.randn(self.n_features , self.n_nodes1)#一層目の重み\n",
    "        network[\"b1\"] = self.sigma * np.random.randn(self.n_nodes1)\n",
    "        network[\"W2\"] = self.sigma * np.random.randn(self.n_nodes1 , self.n_nodes2)#二層目の重み\n",
    "        network[\"b2\"] = self.sigma * np.random.randn(self.n_nodes2)\n",
    "        network[\"W_out\"] = self.sigma * np.random.randn(self.n_nodes2 , self.n_output)#出力層の重み\n",
    "        network[\"b_out\"] =  self.sigma * np.random.randn(self.n_output)\n",
    "        return network\n",
    "    \n",
    "    #活性化関数(シグモイド関数)\n",
    "    def _sigmoid(self , a):\n",
    "        c = np.max(a)\n",
    "        a = a / c\n",
    "        return 1 / (1 + np.exp(-a))\n",
    "    \n",
    "    #活性化関数の微分\n",
    "    def _sigmoid_derivative(self, a):\n",
    "        c = np.max(a)\n",
    "        a = a / c\n",
    "        return (1 - self._sigmoid(a)) * self._sigmoid(a)\n",
    "    \n",
    "    #ソフトマックス関数\n",
    "#     def _softmax(self , a):\n",
    "#         c = np.max(a)\n",
    "#         exp_a = self._sigmoid(a / c)\n",
    "#         sum_exp = np.sum(exp_a)\n",
    "#         z = exp_a / sum_exp\n",
    "#         return z\n",
    "    def _softmax(self , x):\n",
    "        if x.ndim == 2:\n",
    "            x = x.T\n",
    "            x = x - np.max(x, axis=0)\n",
    "            y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "            return y.T\n",
    "        x = x - np.max(x)\n",
    "        return np.exp(x) / np.sum(np.exp(x))\n",
    "    \n",
    "    #フォワードプロバゲーション\n",
    "    def _forward(self ,  X):\n",
    "#         self.get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "#         for self.mini_X_train, self.mini_y_train in self.get_mini_batch:\n",
    "        self.A1 = np.dot(X , self.W1) + self.b1\n",
    "        self.Z1 = self._sigmoid(self.A1)\n",
    "        self.A2 = np.dot(self.Z1 , self.W2) + self.b2\n",
    "        self.Z2 = self._sigmoid(self.A2)\n",
    "        self.A_out = np.dot(self.Z2 , self.W_out) + self.b_out\n",
    "        self.Z_out = self._softmax(self.A_out)\n",
    "        return self.A1,self.A2,self.A_out,self.Z1,self.Z2,self.Z_out\n",
    "\n",
    "    \n",
    "    def _gradient(self , y):\n",
    "        #三層目\n",
    "        delta_3 = self.z_out - y\n",
    "        LB_3 = np.sum(delta_3 , axis = 0)\n",
    "        WL_3 = np.dot(self.z2.T , delta_3)\n",
    "        ZL_2 = np.dot(delta_3 , self.W_out.T)\n",
    "        self.W_out -= self.alpha * WL_3\n",
    "        self.b_out -= self.alpha * LB_3\n",
    "        \n",
    "        #二層目\n",
    "        delta_2 = ZL_2 * self._sigmoid_derivative(self.a2)\n",
    "        LB_2 = np.sum(delta_2 , axis = 0)\n",
    "        WL_2 = np.dot(self.z1.T , delta_2)\n",
    "        ZL_1 = np.dot(delta_2 , self.W2.T)\n",
    "        self.W2 -= self.alpha * WL_2\n",
    "        self.b2 -= self.alpha * LB_2\n",
    "        \n",
    "        #一層目\n",
    "        delta_1 = ZL_1 * self._sigmoid_derivative(self.a1)\n",
    "        LB_1 = np.sum(delta_1 , axis = 0)\n",
    "        WL_1 = np.dot(self.mini_X_train.T , delta_1)\n",
    "        self.W1 -= self.alpha * WL_1\n",
    "        self.b1 -= self.alpha * LB_1\n",
    "#         print(\"ssss\" ,  np.unique(self.W1))\n",
    "        return self.W1 , self.W2,self.W_out,self.b1,self.b2,self.b_out\n",
    "        \n",
    "    #交差エントロピー    \n",
    "    def _cross_entropy_error(self , y):\n",
    "#         if y.ndim == 1: #次元数が１ならば、\n",
    "#             z = z.reshape(1 , self.z.size)\n",
    "#             y = y.reshape(1 , y.size)\n",
    "#         print(\"sssss\",self.z_out[:10,:])\n",
    "        loss = -np.sum(y * np.log(self.z_out) + 1e-7) / self.batch_size\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        np.random.seed(1)\n",
    "        self.network = self.init_network()\n",
    "        self.W1 , self.W2 , self.W_out = self.network[\"W1\"] , self.network[\"W2\"] , self.network[\"W_out\"]\n",
    "        self.b1 , self.b2 , self.b_out = self.network[\"b1\"] , self.network[\"b2\"] , self.network[\"b_out\"]\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            self.get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "            for self.mini_X_train, self.mini_y_train in self.get_mini_batch:\n",
    "            # forward propagation\n",
    "                self.a1,self.a2,self.a_out,self.z1,self.z2,self.z_out = self._forward(self.mini_X_train)\n",
    "                self._grad = self._gradient(self.mini_y_train)\n",
    "                self.c_loss = self._cross_entropy_error(self.mini_y_train)\n",
    "            self.loss = np.append(self.loss , self.c_loss)\n",
    "        \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print(self.W1)\n",
    "\n",
    "    def _predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        self.a1,self.a2,self.a_out,self.z1,self.z2,self.z_out = self._forward(X)\n",
    "        self.y_pred = np.argmax(self.z_out , axis = 1)\n",
    "#         print(self.a2.shape)\n",
    "#         print(self.y_pred.shape)\n",
    "        return self.y_pred\n",
    "    \n",
    "    def accuracy(self , X , t):\n",
    "#         print(\"y\" , y.shape)\n",
    "#         y = np.argmax(y , axis = 0)\n",
    "        y_pred = self._predict(X)\n",
    "#         print(y_pred[:10])\n",
    "\n",
    "#         print(\"t\" , t[:10])\n",
    "        return np.sum(y_pred == t) / float(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchSimpleNeuralNetrowkClassifier(epochs = 30 , alpha = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536e-02 -6.11756414e-03 -5.28171752e-03 ...  9.20615118e-03\n",
      "  -3.53679249e-04  2.11060505e-02]\n",
      " [-1.30653407e-02  7.63804802e-04  3.67231814e-03 ... -7.02920403e-03\n",
      "   7.25550518e-03 -3.24204219e-03]\n",
      " [ 8.14343129e-03  7.80469930e-03 -1.46405357e-02 ... -1.44899155e-02\n",
      "   7.79491866e-03 -1.08630091e-02]\n",
      " ...\n",
      " [ 1.60384584e-02  1.96976176e-02 -2.33649423e-03 ... -6.45457222e-03\n",
      "  -1.15880376e-02 -3.21516920e-03]\n",
      " [ 2.76095121e-03  3.41037846e-03  3.13167564e-03 ...  2.13189768e-02\n",
      "  -8.48780698e-03 -7.04500003e-03]\n",
      " [-1.40223899e-02  3.60829187e-03 -3.59655397e-04 ... -1.01501808e-02\n",
      "   2.21528645e-02 -7.85133601e-05]]\n"
     ]
    }
   ],
   "source": [
    "nn.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】推定\n",
    "推定を行うメソッドを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = ScratchSimpleNeuralNetrowkClassifier(epochs =10 , alpha = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.62434536e-02 -6.11756414e-03 -5.28171752e-03 ...  9.20615118e-03\n",
      "  -3.53679249e-04  2.11060505e-02]\n",
      " [-1.30653407e-02  7.63804802e-04  3.67231814e-03 ... -7.02920403e-03\n",
      "   7.25550518e-03 -3.24204219e-03]\n",
      " [ 8.14343129e-03  7.80469930e-03 -1.46405357e-02 ... -1.44899155e-02\n",
      "   7.79491866e-03 -1.08630091e-02]\n",
      " ...\n",
      " [ 1.60384584e-02  1.96976176e-02 -2.33649423e-03 ... -6.45457222e-03\n",
      "  -1.15880376e-02 -3.21516920e-03]\n",
      " [ 2.76095121e-03  3.41037846e-03  3.13167564e-03 ...  2.13189768e-02\n",
      "  -8.48780698e-03 -7.04500003e-03]\n",
      " [-1.40223899e-02  3.60829187e-03 -3.59655397e-04 ... -1.01501808e-02\n",
      "   2.21528645e-02 -7.85133601e-05]]\n"
     ]
    }
   ],
   "source": [
    "nn.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 6, ..., 7, 7, 4])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn._predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 9, 8, 6])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn._predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.accuracy(X_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 6, ..., 7, 7, 4])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_train , axis = 1)#np.argmaxは最大値のindexを返す関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "【問題7】学習曲線のプロット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c23ea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1 , len(nn.loss) + 1) , nn.loss , label = \"loss\")\n",
    "# plt.plot(np.arange(1 , len(slr.val_loss) + 1) , slr.val_loss , label = \"test_loss\")\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(\"train_loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
